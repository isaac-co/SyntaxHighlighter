<html>
  <head>
    <title>Python Lexical Highliter</title>
    <link rel="stylesheet" href="token_colors.css">
  </head>
  <body>
    <pre><span class="comment">"""
================================================================
Permutation Importance vs Random Forest Feature Importance (MDI)
================================================================

In this example, we will compare the impurity-based feature importance of
:class:`~sklearn.ensemble.RandomForestClassifier` with the
permutation importance on the titanic dataset using
:func:`~sklearn.inspection.permutation_importance`. We will show that the
impurity-based feature importance can inflate the importance of numerical
features.

Furthermore, the impurity-based feature importance of random forests suffers
from being computed on statistics derived from the training dataset: the
importances can be high even for features that are not predictive of the target
variable, as long as the model has the capacity to use them to overfit.

This example shows how to use Permutation Importances as an alternative that
can mitigate those limitations.

.. topic:: References:

   [1] L. Breiman, "Random Forests", Machine Learning, 45(1), 5-32,
       2001. https://doi.org/10.1023/A:1010933404324
"""</span>
<span class="identifier">print</span><span class="grouping">(</span><span class="identifier">__doc__</span><span class="grouping">)</span>
<span class="keyword">import</span> <span class="identifier">matplotlib</span><span class="punctuation">.</span><span class="identifier">pyplot</span> <span class="keyword">as</span> <span class="identifier">plt</span>
<span class="keyword">import</span> <span class="identifier">numpy</span> <span class="keyword">as</span> <span class="identifier">np</span>

<span class="keyword">from</span> <span class="identifier">sklearn</span><span class="punctuation">.</span><span class="identifier">datasets</span> <span class="keyword">import</span> <span class="identifier">fetch_openml</span>
<span class="keyword">from</span> <span class="identifier">sklearn</span><span class="punctuation">.</span><span class="identifier">ensemble</span> <span class="keyword">import</span> <span class="identifier">RandomForestClassifier</span>
<span class="keyword">from</span> <span class="identifier">sklearn</span><span class="punctuation">.</span><span class="identifier">impute</span> <span class="keyword">import</span> <span class="identifier">SimpleImputer</span>
<span class="keyword">from</span> <span class="identifier">sklearn</span><span class="punctuation">.</span><span class="identifier">inspection</span> <span class="keyword">import</span> <span class="identifier">permutation_importance</span>
<span class="keyword">from</span> <span class="identifier">sklearn</span><span class="punctuation">.</span><span class="identifier">compose</span> <span class="keyword">import</span> <span class="identifier">ColumnTransformer</span>
<span class="keyword">from</span> <span class="identifier">sklearn</span><span class="punctuation">.</span><span class="identifier">model_selection</span> <span class="keyword">import</span> <span class="identifier">train_test_split</span>
<span class="keyword">from</span> <span class="identifier">sklearn</span><span class="punctuation">.</span><span class="identifier">pipeline</span> <span class="keyword">import</span> <span class="identifier">Pipeline</span>
<span class="keyword">from</span> <span class="identifier">sklearn</span><span class="punctuation">.</span><span class="identifier">preprocessing</span> <span class="keyword">import</span> <span class="identifier">OneHotEncoder</span>


<span class="comment"># %%</span>
<span class="comment"># Data Loading and Feature Engineering</span>
<span class="comment"># ------------------------------------</span>
<span class="comment"># Let's use pandas to load a copy of the titanic dataset. The following shows</span>
<span class="comment"># how to apply separate preprocessing on numerical and categorical features.</span>
<span class="comment">#</span>
<span class="comment"># We further include two random variables that are not correlated in any way</span>
<span class="comment"># with the target variable (``survived``):</span>
<span class="comment">#</span>
<span class="comment"># - ``random_num`` is a high cardinality numerical variable (as many unique</span>
<span class="comment">#   values as records).</span>
<span class="comment"># - ``random_cat`` is a low cardinality categorical variable (3 possible</span>
<span class="comment">#   values).</span>
<span class="identifier">X</span><span class="punctuation">,</span> <span class="identifier">y</span> <span class="arithmetic-assignment">=</span> <span class="identifier">fetch_openml</span><span class="grouping">(</span><span class="string-literal">"titanic"</span><span class="punctuation">,</span> <span class="identifier">version</span><span class="arithmetic-assignment">=</span><span class="int-literal">1</span><span class="punctuation">,</span> <span class="invalid">a</span><span class="invalid">s</span><span class="invalid">_</span><span class="invalid">f</span><span class="invalid">r</span><span class="invalid">a</span><span class="invalid">m</span><span class="invalid">e</span><span class="arithmetic-assignment">=</span><span class="bool-literal">True</span><span class="punctuation">,</span> <span class="invalid">r</span><span class="invalid">e</span><span class="invalid">t</span><span class="invalid">u</span><span class="invalid">r</span><span class="invalid">n</span><span class="invalid">_</span><span class="invalid">X</span><span class="invalid">_</span><span class="invalid">y</span><span class="arithmetic-assignment">=</span><span class="bool-literal">True</span><span class="grouping">)</span>
<span class="identifier">rng</span> <span class="arithmetic-assignment">=</span> <span class="identifier">np</span><span class="punctuation">.</span><span class="identifier">random</span><span class="punctuation">.</span><span class="identifier">RandomState</span><span class="grouping">(</span><span class="identifier">seed</span><span class="arithmetic-assignment">=</span><span class="int-literal">42</span><span class="grouping">)</span>
<span class="identifier">X</span><span class="grouping">[</span><span class="string-literal">'random_cat'</span><span class="grouping">]</span> <span class="arithmetic-assignment">=</span> <span class="identifier">rng</span><span class="punctuation">.</span><span class="identifier">randint</span><span class="grouping">(</span><span class="int-literal">3</span><span class="punctuation">,</span> <span class="identifier">size</span><span class="arithmetic-assignment">=</span><span class="identifier">X</span><span class="punctuation">.</span><span class="identifier">shape</span><span class="grouping">[</span><span class="int-literal">0</span><span class="grouping">]</span><span class="grouping">)</span>
<span class="identifier">X</span><span class="grouping">[</span><span class="string-literal">'random_num'</span><span class="grouping">]</span> <span class="arithmetic-assignment">=</span> <span class="identifier">rng</span><span class="punctuation">.</span><span class="identifier">randn</span><span class="grouping">(</span><span class="identifier">X</span><span class="punctuation">.</span><span class="identifier">shape</span><span class="grouping">[</span><span class="int-literal">0</span><span class="grouping">]</span><span class="grouping">)</span>

<span class="identifier">categorical_columns</span> <span class="arithmetic-assignment">=</span> <span class="grouping">[</span><span class="string-literal">'pclass', 'sex', 'embarked', 'random_cat'</span><span class="grouping">]</span>
<span class="identifier">numerical_columns</span> <span class="arithmetic-assignment">=</span> <span class="grouping">[</span><span class="string-literal">'age', 'sibsp', 'parch', 'fare', 'random_num'</span><span class="grouping">]</span>

<span class="identifier">X</span> <span class="arithmetic-assignment">=</span> <span class="identifier">X</span><span class="grouping">[</span><span class="identifier">categorical_columns</span> <span class="arithmetic-operator">+</span> <span class="identifier">numerical_columns</span><span class="grouping">]</span>

<span class="identifier">X_train</span><span class="punctuation">,</span> <span class="identifier">X_test</span><span class="punctuation">,</span> <span class="identifier">y_train</span><span class="punctuation">,</span> <span class="identifier">y_test</span> <span class="arithmetic-assignment">=</span> <span class="identifier">train_test_split</span><span class="grouping">(</span>
    <span class="identifier">X</span><span class="punctuation">,</span> <span class="identifier">y</span><span class="punctuation">,</span> <span class="identifier">stratify</span><span class="arithmetic-assignment">=</span><span class="identifier">y</span><span class="punctuation">,</span> <span class="identifier">random_state</span><span class="arithmetic-assignment">=</span><span class="int-literal">42</span><span class="grouping">)</span>

<span class="identifier">categorical_encoder</span> <span class="arithmetic-assignment">=</span> <span class="identifier">OneHotEncoder</span><span class="grouping">(</span><span class="identifier">handle_unknown</span><span class="arithmetic-assignment">=</span><span class="string-literal">'ignore'</span><span class="grouping">)</span>
<span class="identifier">numerical_pipe</span> <span class="arithmetic-assignment">=</span> <span class="identifier">Pipeline</span><span class="grouping">(</span><span class="grouping">[</span>
    <span class="grouping">(</span><span class="string-literal">'imputer', SimpleImputer(strategy='mean'</span><span class="grouping">)</span><span class="grouping">)</span>
<span class="grouping">]</span><span class="grouping">)</span>

<span class="identifier">preprocessing</span> <span class="arithmetic-assignment">=</span> <span class="identifier">ColumnTransformer</span><span class="grouping">(</span>
    <span class="grouping">[</span><span class="grouping">(</span><span class="string-literal">'cat'</span><span class="punctuation">,</span> <span class="identifier">categorical_encoder</span><span class="punctuation">,</span> <span class="identifier">categorical_columns</span><span class="grouping">)</span><span class="punctuation">,</span>
     <span class="grouping">(</span><span class="string-literal">'num'</span><span class="punctuation">,</span> <span class="identifier">numerical_pipe</span><span class="punctuation">,</span> <span class="identifier">numerical_columns</span><span class="grouping">)</span><span class="grouping">]</span><span class="grouping">)</span>

<span class="identifier">rf</span> <span class="arithmetic-assignment">=</span> <span class="identifier">Pipeline</span><span class="grouping">(</span><span class="grouping">[</span>
    <span class="grouping">(</span><span class="string-literal">'preprocess'</span><span class="punctuation">,</span> <span class="identifier">preprocessing</span><span class="grouping">)</span><span class="punctuation">,</span>
    <span class="grouping">(</span><span class="string-literal">'classifier'</span><span class="punctuation">,</span> <span class="identifier">RandomForestClassifier</span><span class="grouping">(</span><span class="identifier">random_state</span><span class="arithmetic-assignment">=</span><span class="int-literal">42</span><span class="grouping">)</span><span class="grouping">)</span>
<span class="grouping">]</span><span class="grouping">)</span>
<span class="identifier">rf</span><span class="punctuation">.</span><span class="identifier">fit</span><span class="grouping">(</span><span class="identifier">X_train</span><span class="punctuation">,</span> <span class="identifier">y_train</span><span class="grouping">)</span>

<span class="comment"># %%</span>
<span class="comment"># Accuracy of the Model</span>
<span class="comment"># ---------------------</span>
<span class="comment"># Prior to inspecting the feature importances, it is important to check that</span>
<span class="comment"># the model predictive performance is high enough. Indeed there would be little</span>
<span class="comment"># interest of inspecting the important features of a non-predictive model.</span>
<span class="comment">#</span>
<span class="comment"># Here one can observe that the train accuracy is very high (the forest model</span>
<span class="comment"># has enough capacity to completely memorize the training set) but it can still</span>
<span class="comment"># generalize well enough to the test set thanks to the built-in bagging of</span>
<span class="comment"># random forests.</span>
<span class="comment">#</span>
<span class="comment"># It might be possible to trade some accuracy on the training set for a</span>
<span class="comment"># slightly better accuracy on the test set by limiting the capacity of the</span>
<span class="comment"># trees (for instance by setting ``min_samples_leaf=5`` or</span>
<span class="comment"># ``min_samples_leaf=10``) so as to limit overfitting while not introducing too</span>
<span class="comment"># much underfitting.</span>
<span class="comment">#</span>
<span class="comment"># However let's keep our high capacity random forest model for now so as to</span>
<span class="comment"># illustrate some pitfalls with feature importance on variables with many</span>
<span class="comment"># unique values.</span>
<span class="identifier">print</span><span class="grouping">(</span><span class="string-literal">"RF train accuracy: %0.3f"</span> <span class="arithmetic-operator">%</span> <span class="identifier">rf</span><span class="punctuation">.</span><span class="identifier">score</span><span class="grouping">(</span><span class="identifier">X_train</span><span class="punctuation">,</span> <span class="identifier">y_train</span><span class="grouping">)</span><span class="grouping">)</span>
<span class="identifier">print</span><span class="grouping">(</span><span class="string-literal">"RF test accuracy: %0.3f"</span> <span class="arithmetic-operator">%</span> <span class="identifier">rf</span><span class="punctuation">.</span><span class="identifier">score</span><span class="grouping">(</span><span class="identifier">X_test</span><span class="punctuation">,</span> <span class="identifier">y_test</span><span class="grouping">)</span><span class="grouping">)</span>


<span class="comment"># %%</span>
<span class="comment"># Tree's Feature Importance from Mean Decrease in Impurity (MDI)</span>
<span class="comment"># --------------------------------------------------------------</span>
<span class="comment"># The impurity-based feature importance ranks the numerical features to be the</span>
<span class="comment"># most important features. As a result, the non-predictive ``random_num``</span>
<span class="comment"># variable is ranked the most important!</span>
<span class="comment">#</span>
<span class="comment"># This problem stems from two limitations of impurity-based feature</span>
<span class="comment"># importances:</span>
<span class="comment">#</span>
<span class="comment"># - impurity-based importances are biased towards high cardinality features;</span>
<span class="comment"># - impurity-based importances are computed on training set statistics and</span>
<span class="comment">#   therefore do not reflect the ability of feature to be useful to make</span>
<span class="comment">#   predictions that generalize to the test set (when the model has enough</span>
<span class="comment">#   capacity).</span>
<span class="identifier">ohe</span> <span class="arithmetic-assignment">=</span> <span class="grouping">(</span><span class="identifier">rf</span><span class="punctuation">.</span><span class="identifier">named_steps</span><span class="grouping">[</span><span class="string-literal">'preprocess'</span><span class="grouping">]</span>
         <span class="punctuation">.</span><span class="identifier">named_transformers_</span><span class="grouping">[</span><span class="string-literal">'cat'</span><span class="grouping">]</span><span class="grouping">)</span>
<span class="identifier">feature_names</span> <span class="arithmetic-assignment">=</span> <span class="identifier">ohe</span><span class="punctuation">.</span><span class="identifier">get_feature_names</span><span class="grouping">(</span><span class="identifier">input_features</span><span class="arithmetic-assignment">=</span><span class="identifier">categorical_columns</span><span class="grouping">)</span>
<span class="identifier">feature_names</span> <span class="arithmetic-assignment">=</span> <span class="identifier">np</span><span class="punctuation">.</span><span class="identifier">r_</span><span class="grouping">[</span><span class="identifier">feature_names</span><span class="punctuation">,</span> <span class="identifier">numerical_columns</span><span class="grouping">]</span>

<span class="identifier">tree_feature_importances</span> <span class="arithmetic-assignment">=</span> <span class="grouping">(</span>
    <span class="identifier">rf</span><span class="punctuation">.</span><span class="identifier">named_steps</span><span class="grouping">[</span><span class="string-literal">'classifier'</span><span class="grouping">]</span><span class="punctuation">.</span><span class="identifier">feature_importances_</span><span class="grouping">)</span>
<span class="identifier">sorted_idx</span> <span class="arithmetic-assignment">=</span> <span class="identifier">tree_feature_importances</span><span class="punctuation">.</span><span class="identifier">argsort</span><span class="grouping">(</span><span class="grouping">)</span>

<span class="identifier">y_ticks</span> <span class="arithmetic-assignment">=</span> <span class="identifier">np</span><span class="punctuation">.</span><span class="identifier">arange</span><span class="grouping">(</span><span class="int-literal">0</span><span class="punctuation">,</span> <span class="identifier">len</span><span class="grouping">(</span><span class="identifier">feature_names</span><span class="grouping">)</span><span class="grouping">)</span>
<span class="identifier">fig</span><span class="punctuation">,</span> <span class="identifier">ax</span> <span class="arithmetic-assignment">=</span> <span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">subplots</span><span class="grouping">(</span><span class="grouping">)</span>
<span class="identifier">ax</span><span class="punctuation">.</span><span class="identifier">barh</span><span class="grouping">(</span><span class="identifier">y_ticks</span><span class="punctuation">,</span> <span class="identifier">tree_feature_importances</span><span class="grouping">[</span><span class="identifier">sorted_idx</span><span class="grouping">]</span><span class="grouping">)</span>
<span class="identifier">ax</span><span class="punctuation">.</span><span class="identifier">set_yticks</span><span class="grouping">(</span><span class="identifier">y_ticks</span><span class="grouping">)</span>
<span class="identifier">ax</span><span class="punctuation">.</span><span class="identifier">set_yticklabels</span><span class="grouping">(</span><span class="identifier">feature_names</span><span class="grouping">[</span><span class="identifier">sorted_idx</span><span class="grouping">]</span><span class="grouping">)</span>
<span class="identifier">ax</span><span class="punctuation">.</span><span class="identifier">set_title</span><span class="grouping">(</span><span class="string-literal">"Random Forest Feature Importances (MDI)"</span><span class="grouping">)</span>
<span class="identifier">fig</span><span class="punctuation">.</span><span class="identifier">tight_layout</span><span class="grouping">(</span><span class="grouping">)</span>
<span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">show</span><span class="grouping">(</span><span class="grouping">)</span>


<span class="comment"># %%</span>
<span class="comment"># As an alternative, the permutation importances of ``rf`` are computed on a</span>
<span class="comment"># held out test set. This shows that the low cardinality categorical feature,</span>
<span class="comment"># ``sex`` is the most important feature.</span>
<span class="comment">#</span>
<span class="comment"># Also note that both random features have very low importances (close to 0) as</span>
<span class="comment"># expected.</span>
<span class="identifier">result</span> <span class="arithmetic-assignment">=</span> <span class="identifier">permutation_importance</span><span class="grouping">(</span><span class="identifier">rf</span><span class="punctuation">,</span> <span class="identifier">X_test</span><span class="punctuation">,</span> <span class="identifier">y_test</span><span class="punctuation">,</span> <span class="identifier">n_repeats</span><span class="arithmetic-assignment">=</span><span class="int-literal">10</span><span class="punctuation">,</span>
                                <span class="identifier">random_state</span><span class="arithmetic-assignment">=</span><span class="int-literal">42</span><span class="punctuation">,</span> <span class="identifier">n_jobs</span><span class="arithmetic-assignment">=</span><span class="int-literal">2</span><span class="grouping">)</span>
<span class="identifier">sorted_idx</span> <span class="arithmetic-assignment">=</span> <span class="identifier">result</span><span class="punctuation">.</span><span class="invalid">i</span><span class="invalid">m</span><span class="invalid">p</span><span class="invalid">o</span><span class="invalid">r</span><span class="invalid">t</span><span class="invalid">a</span><span class="invalid">n</span><span class="invalid">c</span><span class="invalid">e</span><span class="invalid">s</span><span class="invalid">_</span><span class="invalid">m</span><span class="invalid">e</span><span class="invalid">a</span><span class="invalid">n</span><span class="punctuation">.</span><span class="identifier">argsort</span><span class="grouping">(</span><span class="grouping">)</span>

<span class="identifier">fig</span><span class="punctuation">,</span> <span class="identifier">ax</span> <span class="arithmetic-assignment">=</span> <span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">subplots</span><span class="grouping">(</span><span class="grouping">)</span>
<span class="identifier">ax</span><span class="punctuation">.</span><span class="identifier">boxplot</span><span class="grouping">(</span><span class="identifier">result</span><span class="punctuation">.</span><span class="invalid">i</span><span class="invalid">m</span><span class="invalid">p</span><span class="invalid">o</span><span class="invalid">r</span><span class="invalid">t</span><span class="invalid">a</span><span class="invalid">n</span><span class="invalid">c</span><span class="invalid">e</span><span class="invalid">s</span><span class="grouping">[</span><span class="identifier">sorted_idx</span><span class="grouping">]</span><span class="punctuation">.</span><span class="identifier">T</span><span class="punctuation">,</span>
           <span class="identifier">vert</span><span class="arithmetic-assignment">=</span><span class="bool-literal">False</span><span class="punctuation">,</span> <span class="identifier">labels</span><span class="arithmetic-assignment">=</span><span class="identifier">X_test</span><span class="punctuation">.</span><span class="identifier">columns</span><span class="grouping">[</span><span class="identifier">sorted_idx</span><span class="grouping">]</span><span class="grouping">)</span>
<span class="identifier">ax</span><span class="punctuation">.</span><span class="identifier">set_title</span><span class="grouping">(</span><span class="string-literal">"Permutation Importances (test set)"</span><span class="grouping">)</span>
<span class="identifier">fig</span><span class="punctuation">.</span><span class="identifier">tight_layout</span><span class="grouping">(</span><span class="grouping">)</span>
<span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">show</span><span class="grouping">(</span><span class="grouping">)</span>

<span class="comment"># %%</span>
<span class="comment"># It is also possible to compute the permutation importances on the training</span>
<span class="comment"># set. This reveals that ``random_num`` gets a significantly higher importance</span>
<span class="comment"># ranking than when computed on the test set. The difference between those two</span>
<span class="comment"># plots is a confirmation that the RF model has enough capacity to use that</span>
<span class="comment"># random numerical feature to overfit. You can further confirm this by</span>
<span class="comment"># re-running this example with constrained RF with min_samples_leaf=10.</span>
<span class="identifier">result</span> <span class="arithmetic-assignment">=</span> <span class="identifier">permutation_importance</span><span class="grouping">(</span><span class="identifier">rf</span><span class="punctuation">,</span> <span class="identifier">X_train</span><span class="punctuation">,</span> <span class="identifier">y_train</span><span class="punctuation">,</span> <span class="identifier">n_repeats</span><span class="arithmetic-assignment">=</span><span class="int-literal">10</span><span class="punctuation">,</span>
                                <span class="identifier">random_state</span><span class="arithmetic-assignment">=</span><span class="int-literal">42</span><span class="punctuation">,</span> <span class="identifier">n_jobs</span><span class="arithmetic-assignment">=</span><span class="int-literal">2</span><span class="grouping">)</span>
<span class="identifier">sorted_idx</span> <span class="arithmetic-assignment">=</span> <span class="identifier">result</span><span class="punctuation">.</span><span class="invalid">i</span><span class="invalid">m</span><span class="invalid">p</span><span class="invalid">o</span><span class="invalid">r</span><span class="invalid">t</span><span class="invalid">a</span><span class="invalid">n</span><span class="invalid">c</span><span class="invalid">e</span><span class="invalid">s</span><span class="invalid">_</span><span class="invalid">m</span><span class="invalid">e</span><span class="invalid">a</span><span class="invalid">n</span><span class="punctuation">.</span><span class="identifier">argsort</span><span class="grouping">(</span><span class="grouping">)</span>

<span class="identifier">fig</span><span class="punctuation">,</span> <span class="identifier">ax</span> <span class="arithmetic-assignment">=</span> <span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">subplots</span><span class="grouping">(</span><span class="grouping">)</span>
<span class="identifier">ax</span><span class="punctuation">.</span><span class="identifier">boxplot</span><span class="grouping">(</span><span class="identifier">result</span><span class="punctuation">.</span><span class="invalid">i</span><span class="invalid">m</span><span class="invalid">p</span><span class="invalid">o</span><span class="invalid">r</span><span class="invalid">t</span><span class="invalid">a</span><span class="invalid">n</span><span class="invalid">c</span><span class="invalid">e</span><span class="invalid">s</span><span class="grouping">[</span><span class="identifier">sorted_idx</span><span class="grouping">]</span><span class="punctuation">.</span><span class="identifier">T</span><span class="punctuation">,</span>
           <span class="identifier">vert</span><span class="arithmetic-assignment">=</span><span class="bool-literal">False</span><span class="punctuation">,</span> <span class="identifier">labels</span><span class="arithmetic-assignment">=</span><span class="identifier">X_train</span><span class="punctuation">.</span><span class="identifier">columns</span><span class="grouping">[</span><span class="identifier">sorted_idx</span><span class="grouping">]</span><span class="grouping">)</span>
<span class="identifier">ax</span><span class="punctuation">.</span><span class="identifier">set_title</span><span class="grouping">(</span><span class="string-literal">"Permutation Importances (train set)"</span><span class="grouping">)</span>
<span class="identifier">fig</span><span class="punctuation">.</span><span class="identifier">tight_layout</span><span class="grouping">(</span><span class="grouping">)</span>
<span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">show</span><span class="grouping">(</span><span class="grouping">)</span>

    </pre>
  </body>
</html>
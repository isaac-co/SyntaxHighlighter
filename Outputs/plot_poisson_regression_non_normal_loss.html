<html>
  <head>
    <title>Python Lexical Highliter</title>
    <link rel="stylesheet" href="token_colors.css">
  </head>
  <body>
    <pre><span class="comment">"""
======================================
Poisson regression and non-normal loss
======================================

This example illustrates the use of log-linear Poisson regression on the
`French Motor Third-Party Liability Claims dataset
&lt;https://www.openml.org/d/41214&gt;`_ from [1]_ and compares it with a linear
model fitted with the usual least squared error and a non-linear GBRT model
fitted with the Poisson loss (and a log-link).

A few definitions:

- A **policy** is a contract between an insurance company and an individual:
  the **policyholder**, that is, the vehicle driver in this case.

- A **claim** is the request made by a policyholder to the insurer to
  compensate for a loss covered by the insurance.

- The **exposure** is the duration of the insurance coverage of a given policy,
  in years.

- The claim **frequency** is the number of claims divided by the exposure,
  typically measured in number of claims per year.

In this dataset, each sample corresponds to an insurance policy. Available
features include driver age, vehicle age, vehicle power, etc.

Our goal is to predict the expected frequency of claims following car accidents
for a new policyholder given the historical data over a population of
policyholders.

.. [1]  A. Noll, R. Salzmann and M.V. Wuthrich, Case Study: French Motor
    Third-Party Liability Claims (November 8, 2018). `doi:10.2139/ssrn.3164764
    &lt;http://dx.doi.org/10.2139/ssrn.3164764&gt;`_

"""</span>
<span class="identifier">print</span><span class="grouping">(</span><span class="identifier">__doc__</span><span class="grouping">)</span>
<span class="comment"># Authors: Christian Lorentzen &lt;lorentzen.ch@gmail.com&gt;</span>
<span class="comment">#          Roman Yurchak &lt;rth.yurchak@gmail.com&gt;</span>
<span class="comment">#          Olivier Grisel &lt;olivier.grisel@ensta.org&gt;</span>
<span class="comment"># License: BSD 3 clause</span>
<span class="keyword">import</span> <span class="identifier">numpy</span> <span class="keyword">as</span> <span class="identifier">np</span>
<span class="keyword">import</span> <span class="identifier">matplotlib</span><span class="punctuation">.</span><span class="identifier">pyplot</span> <span class="keyword">as</span> <span class="identifier">plt</span>
<span class="keyword">import</span> <span class="identifier">pandas</span> <span class="keyword">as</span> <span class="identifier">pd</span>


<span class="comment">##############################################################################</span>
<span class="comment"># The French Motor Third-Party Liability Claims dataset</span>
<span class="comment"># -----------------------------------------------------</span>
<span class="comment">#</span>
<span class="comment"># Let's load the motor claim dataset from OpenML:</span>
<span class="comment"># https://www.openml.org/d/41214</span>

<span class="keyword">from</span> <span class="identifier">sklearn</span><span class="punctuation">.</span><span class="identifier">datasets</span> <span class="keyword">import</span> <span class="identifier">fetch_openml</span>


<span class="identifier">df</span> <span class="arithmetic-assignment">=</span> <span class="identifier">fetch_openml</span><span class="grouping">(</span><span class="identifier">data_id</span><span class="arithmetic-assignment">=</span><span class="int-literal">41214</span><span class="punctuation">,</span> <span class="invalid">a</span><span class="invalid">s</span><span class="invalid">_</span><span class="invalid">f</span><span class="invalid">r</span><span class="invalid">a</span><span class="invalid">m</span><span class="invalid">e</span><span class="arithmetic-assignment">=</span><span class="bool-literal">True</span><span class="grouping">)</span><span class="punctuation">.</span><span class="identifier">frame</span>
<span class="identifier">df</span>

<span class="comment"># %%</span>
<span class="comment"># The number of claims (``ClaimNb``) is a positive integer that can be modeled</span>
<span class="comment"># as a Poisson distribution. It is then assumed to be the number of discrete</span>
<span class="comment"># events occurring with a constant rate in a given time interval (``Exposure``,</span>
<span class="comment"># in units of years).</span>
<span class="comment">#</span>
<span class="comment"># Here we want to model the frequency ``y = ClaimNb / Exposure`` conditionally</span>
<span class="comment"># on ``X`` via a (scaled) Poisson distribution, and use ``Exposure`` as</span>
<span class="comment"># ``sample_weight``.</span>

<span class="identifier">df</span><span class="grouping">[</span><span class="string-literal">"Frequency"] = df["ClaimNb"] / df["Exposure"</span><span class="grouping">]</span>

<span class="identifier">print</span><span class="grouping">(</span><span class="string-literal">"Average Frequency = {}"</span>
      <span class="punctuation">.</span><span class="invalid">f</span><span class="invalid">o</span><span class="invalid">r</span><span class="invalid">m</span><span class="invalid">a</span><span class="invalid">t</span><span class="grouping">(</span><span class="identifier">np</span><span class="punctuation">.</span><span class="identifier">average</span><span class="grouping">(</span><span class="identifier">df</span><span class="grouping">[</span><span class="string-literal">"Frequency"], weights=df["Exposure"</span><span class="grouping">]</span><span class="grouping">)</span><span class="grouping">)</span><span class="grouping">)</span>

<span class="identifier">print</span><span class="grouping">(</span><span class="string-literal">"Fraction of exposure with zero claims = {0:.1%}"</span>
      <span class="punctuation">.</span><span class="invalid">f</span><span class="invalid">o</span><span class="invalid">r</span><span class="invalid">m</span><span class="invalid">a</span><span class="invalid">t</span><span class="grouping">(</span><span class="identifier">df</span><span class="punctuation">.</span><span class="identifier">loc</span><span class="grouping">[</span><span class="identifier">df</span><span class="grouping">[</span><span class="string-literal">"ClaimNb"] == 0, "Exposure"</span><span class="grouping">]</span><span class="punctuation">.</span><span class="identifier">sum</span><span class="grouping">(</span><span class="grouping">)</span> <span class="arithmetic-operator">/</span>
              <span class="identifier">df</span><span class="grouping">[</span><span class="string-literal">"Exposure"</span><span class="grouping">]</span><span class="punctuation">.</span><span class="identifier">sum</span><span class="grouping">(</span><span class="grouping">)</span><span class="grouping">)</span><span class="grouping">)</span>

<span class="identifier">fig</span><span class="punctuation">,</span> <span class="grouping">(</span><span class="identifier">ax0</span><span class="punctuation">,</span> <span class="identifier">ax1</span><span class="punctuation">,</span> <span class="identifier">ax2</span><span class="grouping">)</span> <span class="arithmetic-assignment">=</span> <span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">subplots</span><span class="grouping">(</span><span class="identifier">ncols</span><span class="arithmetic-assignment">=</span><span class="int-literal">3</span><span class="punctuation">,</span> <span class="identifier">figsize</span><span class="arithmetic-assignment">=</span><span class="grouping">(</span><span class="int-literal">16</span><span class="punctuation">,</span> <span class="int-literal">4</span><span class="grouping">)</span><span class="grouping">)</span>
<span class="identifier">ax0</span><span class="punctuation">.</span><span class="identifier">set_title</span><span class="grouping">(</span><span class="string-literal">"Number of claims"</span><span class="grouping">)</span>
<span class="identifier">_</span> <span class="arithmetic-assignment">=</span> <span class="identifier">df</span><span class="grouping">[</span><span class="string-literal">"ClaimNb"</span><span class="grouping">]</span><span class="punctuation">.</span><span class="identifier">hist</span><span class="grouping">(</span><span class="identifier">bins</span><span class="arithmetic-assignment">=</span><span class="int-literal">30</span><span class="punctuation">,</span> <span class="identifier">log</span><span class="arithmetic-assignment">=</span><span class="bool-literal">True</span><span class="punctuation">,</span> <span class="identifier">ax</span><span class="arithmetic-assignment">=</span><span class="identifier">ax0</span><span class="grouping">)</span>
<span class="identifier">ax1</span><span class="punctuation">.</span><span class="identifier">set_title</span><span class="grouping">(</span><span class="string-literal">"Exposure in years"</span><span class="grouping">)</span>
<span class="identifier">_</span> <span class="arithmetic-assignment">=</span> <span class="identifier">df</span><span class="grouping">[</span><span class="string-literal">"Exposure"</span><span class="grouping">]</span><span class="punctuation">.</span><span class="identifier">hist</span><span class="grouping">(</span><span class="identifier">bins</span><span class="arithmetic-assignment">=</span><span class="int-literal">30</span><span class="punctuation">,</span> <span class="identifier">log</span><span class="arithmetic-assignment">=</span><span class="bool-literal">True</span><span class="punctuation">,</span> <span class="identifier">ax</span><span class="arithmetic-assignment">=</span><span class="identifier">ax1</span><span class="grouping">)</span>
<span class="identifier">ax2</span><span class="punctuation">.</span><span class="identifier">set_title</span><span class="grouping">(</span><span class="string-literal">"Frequency (number of claims per year)"</span><span class="grouping">)</span>
<span class="identifier">_</span> <span class="arithmetic-assignment">=</span> <span class="identifier">df</span><span class="grouping">[</span><span class="string-literal">"Frequency"</span><span class="grouping">]</span><span class="punctuation">.</span><span class="identifier">hist</span><span class="grouping">(</span><span class="identifier">bins</span><span class="arithmetic-assignment">=</span><span class="int-literal">30</span><span class="punctuation">,</span> <span class="identifier">log</span><span class="arithmetic-assignment">=</span><span class="bool-literal">True</span><span class="punctuation">,</span> <span class="identifier">ax</span><span class="arithmetic-assignment">=</span><span class="identifier">ax2</span><span class="grouping">)</span>

<span class="comment"># %%</span>
<span class="comment"># The remaining columns can be used to predict the frequency of claim events.</span>
<span class="comment"># Those columns are very heterogeneous with a mix of categorical and numeric</span>
<span class="comment"># variables with different scales, possibly very unevenly distributed.</span>
<span class="comment">#</span>
<span class="comment"># In order to fit linear models with those predictors it is therefore</span>
<span class="comment"># necessary to perform standard feature transformations as follows:</span>

<span class="keyword">from</span> <span class="identifier">sklearn</span><span class="punctuation">.</span><span class="identifier">pipeline</span> <span class="keyword">import</span> <span class="identifier">make_pipeline</span>
<span class="keyword">from</span> <span class="identifier">sklearn</span><span class="punctuation">.</span><span class="identifier">preprocessing</span> <span class="keyword">import</span> <span class="identifier">FunctionTransformer</span><span class="punctuation">,</span> <span class="identifier">OneHotEncoder</span>
<span class="keyword">from</span> <span class="identifier">sklearn</span><span class="punctuation">.</span><span class="identifier">preprocessing</span> <span class="keyword">import</span> <span class="identifier">StandardScaler</span><span class="punctuation">,</span> <span class="identifier">KBinsDiscretizer</span>
<span class="keyword">from</span> <span class="identifier">sklearn</span><span class="punctuation">.</span><span class="identifier">compose</span> <span class="keyword">import</span> <span class="identifier">ColumnTransformer</span>


<span class="identifier">log_scale_transformer</span> <span class="arithmetic-assignment">=</span> <span class="identifier">make_pipeline</span><span class="grouping">(</span>
    <span class="identifier">FunctionTransformer</span><span class="grouping">(</span><span class="identifier">np</span><span class="punctuation">.</span><span class="identifier">log</span><span class="punctuation">,</span> <span class="identifier">validate</span><span class="arithmetic-assignment">=</span><span class="bool-literal">False</span><span class="grouping">)</span><span class="punctuation">,</span>
    <span class="identifier">StandardScaler</span><span class="grouping">(</span><span class="grouping">)</span>
<span class="grouping">)</span>

<span class="identifier">linear_model_preprocessor</span> <span class="arithmetic-assignment">=</span> <span class="identifier">ColumnTransformer</span><span class="grouping">(</span>
    <span class="grouping">[</span>
        <span class="grouping">(</span><span class="string-literal">"passthrough_numeric", "passthrough"</span><span class="punctuation">,</span>
            <span class="grouping">[</span><span class="string-literal">"BonusMalus"</span><span class="grouping">]</span><span class="grouping">)</span><span class="punctuation">,</span>
        <span class="grouping">(</span><span class="string-literal">"binned_numeric"</span><span class="punctuation">,</span> <span class="identifier">KBinsDiscretizer</span><span class="grouping">(</span><span class="identifier">n_bins</span><span class="arithmetic-assignment">=</span><span class="int-literal">10</span><span class="grouping">)</span><span class="punctuation">,</span>
            <span class="grouping">[</span><span class="string-literal">"VehAge", "DrivAge"</span><span class="grouping">]</span><span class="grouping">)</span><span class="punctuation">,</span>
        <span class="grouping">(</span><span class="string-literal">"log_scaled_numeric"</span><span class="punctuation">,</span> <span class="identifier">log_scale_transformer</span><span class="punctuation">,</span>
            <span class="grouping">[</span><span class="string-literal">"Density"</span><span class="grouping">]</span><span class="grouping">)</span><span class="punctuation">,</span>
        <span class="grouping">(</span><span class="string-literal">"onehot_categorical"</span><span class="punctuation">,</span> <span class="identifier">OneHotEncoder</span><span class="grouping">(</span><span class="grouping">)</span><span class="punctuation">,</span>
            <span class="grouping">[</span><span class="string-literal">"VehBrand", "VehPower", "VehGas", "Region", "Area"</span><span class="grouping">]</span><span class="grouping">)</span><span class="punctuation">,</span>
    <span class="grouping">]</span><span class="punctuation">,</span>
    <span class="identifier">remainder</span><span class="arithmetic-assignment">=</span><span class="string-literal">"drop"</span><span class="punctuation">,</span>
<span class="grouping">)</span>

<span class="comment"># %%</span>
<span class="comment"># A constant prediction baseline</span>
<span class="comment"># ------------------------------</span>
<span class="comment">#</span>
<span class="comment"># It is worth noting that more than 93% of policyholders have zero claims. If</span>
<span class="comment"># we were to convert this problem into a binary classification task, it would</span>
<span class="comment"># be significantly imbalanced, and even a simplistic model that would only</span>
<span class="comment"># predict mean can achieve an accuracy of 93%.</span>
<span class="comment">#</span>
<span class="comment"># To evaluate the pertinence of the used metrics, we will consider as a</span>
<span class="comment"># baseline a "dummy" estimator that constantly predicts the mean frequency of</span>
<span class="comment"># the training sample.</span>

<span class="keyword">from</span> <span class="identifier">sklearn</span><span class="punctuation">.</span><span class="identifier">dummy</span> <span class="keyword">import</span> <span class="identifier">DummyRegressor</span>
<span class="keyword">from</span> <span class="identifier">sklearn</span><span class="punctuation">.</span><span class="identifier">pipeline</span> <span class="keyword">import</span> <span class="identifier">Pipeline</span>
<span class="keyword">from</span> <span class="identifier">sklearn</span><span class="punctuation">.</span><span class="identifier">model_selection</span> <span class="keyword">import</span> <span class="identifier">train_test_split</span>

<span class="identifier">df_train</span><span class="punctuation">,</span> <span class="identifier">df_test</span> <span class="arithmetic-assignment">=</span> <span class="identifier">train_test_split</span><span class="grouping">(</span><span class="identifier">df</span><span class="punctuation">,</span> <span class="identifier">test_size</span><span class="arithmetic-assignment">=</span><span class="float-literal">0.33</span><span class="punctuation">,</span> <span class="identifier">random_state</span><span class="arithmetic-assignment">=</span><span class="int-literal">0</span><span class="grouping">)</span>

<span class="identifier">dummy</span> <span class="arithmetic-assignment">=</span> <span class="identifier">Pipeline</span><span class="grouping">(</span><span class="grouping">[</span>
    <span class="grouping">(</span><span class="string-literal">"preprocessor"</span><span class="punctuation">,</span> <span class="identifier">linear_model_preprocessor</span><span class="grouping">)</span><span class="punctuation">,</span>
    <span class="grouping">(</span><span class="string-literal">"regressor"</span><span class="punctuation">,</span> <span class="identifier">DummyRegressor</span><span class="grouping">(</span><span class="identifier">strategy</span><span class="arithmetic-assignment">=</span><span class="string-literal">'mean'</span><span class="grouping">)</span><span class="grouping">)</span><span class="punctuation">,</span>
<span class="grouping">]</span><span class="grouping">)</span><span class="punctuation">.</span><span class="identifier">fit</span><span class="grouping">(</span><span class="identifier">df_train</span><span class="punctuation">,</span> <span class="identifier">df_train</span><span class="grouping">[</span><span class="string-literal">"Frequency"</span><span class="grouping">]</span><span class="punctuation">,</span>
       <span class="identifier">regressor__sample_weight</span><span class="arithmetic-assignment">=</span><span class="identifier">df_train</span><span class="grouping">[</span><span class="string-literal">"Exposure"</span><span class="grouping">]</span><span class="grouping">)</span>


<span class="comment">##############################################################################</span>
<span class="comment"># Let's compute the performance of this constant prediction baseline with 3</span>
<span class="comment"># different regression metrics:</span>

<span class="keyword">from</span> <span class="identifier">sklearn</span><span class="punctuation">.</span><span class="identifier">metrics</span> <span class="keyword">import</span> <span class="identifier">mean_squared_error</span>
<span class="keyword">from</span> <span class="identifier">sklearn</span><span class="punctuation">.</span><span class="identifier">metrics</span> <span class="keyword">import</span> <span class="identifier">mean_absolute_error</span>
<span class="keyword">from</span> <span class="identifier">sklearn</span><span class="punctuation">.</span><span class="identifier">metrics</span> <span class="keyword">import</span> <span class="identifier">mean_poisson_deviance</span>


<span class="keyword">def</span> <span class="identifier">score_estimator</span><span class="grouping">(</span><span class="identifier">estimator</span><span class="punctuation">,</span> <span class="identifier">df_test</span><span class="grouping">)</span><span class="punctuation">:</span>
    <span class="comment">"""Score an estimator on the test set."""</span>
    <span class="identifier">y_pred</span> <span class="arithmetic-assignment">=</span> <span class="identifier">estimator</span><span class="punctuation">.</span><span class="identifier">predict</span><span class="grouping">(</span><span class="identifier">df_test</span><span class="grouping">)</span>

    <span class="identifier">print</span><span class="grouping">(</span><span class="string-literal">"MSE: %.3f"</span> <span class="arithmetic-operator">%</span>
          <span class="identifier">mean_squared_error</span><span class="grouping">(</span><span class="identifier">df_test</span><span class="grouping">[</span><span class="string-literal">"Frequency"</span><span class="grouping">]</span><span class="punctuation">,</span> <span class="identifier">y_pred</span><span class="punctuation">,</span>
                             <span class="identifier">sample_weight</span><span class="arithmetic-assignment">=</span><span class="identifier">df_test</span><span class="grouping">[</span><span class="string-literal">"Exposure"</span><span class="grouping">]</span><span class="grouping">)</span><span class="grouping">)</span>
    <span class="identifier">print</span><span class="grouping">(</span><span class="string-literal">"MAE: %.3f"</span> <span class="arithmetic-operator">%</span>
          <span class="identifier">mean_absolute_error</span><span class="grouping">(</span><span class="identifier">df_test</span><span class="grouping">[</span><span class="string-literal">"Frequency"</span><span class="grouping">]</span><span class="punctuation">,</span> <span class="identifier">y_pred</span><span class="punctuation">,</span>
                              <span class="identifier">sample_weight</span><span class="arithmetic-assignment">=</span><span class="identifier">df_test</span><span class="grouping">[</span><span class="string-literal">"Exposure"</span><span class="grouping">]</span><span class="grouping">)</span><span class="grouping">)</span>

    <span class="comment"># Ignore non-positive predictions, as they are invalid for</span>
    <span class="comment"># the Poisson deviance.</span>
    <span class="identifier">mask</span> <span class="arithmetic-assignment">=</span> <span class="identifier">y_pred</span> <span class="relational-operator">&gt;</span> <span class="int-literal">0</span>
    <span class="keyword">if</span> <span class="grouping">(</span><span class="bitwise-operator">~</span><span class="identifier">mask</span><span class="grouping">)</span><span class="punctuation">.</span><span class="identifier">any</span><span class="grouping">(</span><span class="grouping">)</span><span class="punctuation">:</span>
        <span class="identifier">n_masked</span><span class="punctuation">,</span> <span class="identifier">n_samples</span> <span class="arithmetic-assignment">=</span> <span class="grouping">(</span><span class="bitwise-operator">~</span><span class="identifier">mask</span><span class="grouping">)</span><span class="punctuation">.</span><span class="identifier">sum</span><span class="grouping">(</span><span class="grouping">)</span><span class="punctuation">,</span> <span class="identifier">mask</span><span class="punctuation">.</span><span class="identifier">shape</span><span class="grouping">[</span><span class="int-literal">0</span><span class="grouping">]</span>
        <span class="identifier">print</span><span class="grouping">(</span><span class="identifier">f</span><span class="string-literal">"WARNING: Estimator yields invalid, non-positive predictions "</span>
              <span class="identifier">f</span><span class="string-literal">" for {n_masked} samples out of {n_samples}. These predictions "</span>
              <span class="identifier">f</span><span class="string-literal">"are ignored when computing the Poisson deviance."</span><span class="grouping">)</span>

    <span class="identifier">print</span><span class="grouping">(</span><span class="string-literal">"mean Poisson deviance: %.3f"</span> <span class="arithmetic-operator">%</span>
          <span class="identifier">mean_poisson_deviance</span><span class="grouping">(</span><span class="identifier">df_test</span><span class="grouping">[</span><span class="string-literal">"Frequency"</span><span class="grouping">]</span><span class="grouping">[</span><span class="identifier">mask</span><span class="grouping">]</span><span class="punctuation">,</span>
                                <span class="identifier">y_pred</span><span class="grouping">[</span><span class="identifier">mask</span><span class="grouping">]</span><span class="punctuation">,</span>
                                <span class="identifier">sample_weight</span><span class="arithmetic-assignment">=</span><span class="identifier">df_test</span><span class="grouping">[</span><span class="string-literal">"Exposure"</span><span class="grouping">]</span><span class="grouping">[</span><span class="identifier">mask</span><span class="grouping">]</span><span class="grouping">)</span><span class="grouping">)</span>


<span class="identifier">print</span><span class="grouping">(</span><span class="string-literal">"Constant mean frequency evaluation:"</span><span class="grouping">)</span>
<span class="identifier">score_estimator</span><span class="grouping">(</span><span class="identifier">dummy</span><span class="punctuation">,</span> <span class="identifier">df_test</span><span class="grouping">)</span>

<span class="comment"># %%</span>
<span class="comment"># (Generalized) linear models</span>
<span class="comment"># ---------------------------</span>
<span class="comment">#</span>
<span class="comment"># We start by modeling the target variable with the (l2 penalized) least</span>
<span class="comment"># squares linear regression model, more comonly known as Ridge regression. We</span>
<span class="comment"># use a low penalization `alpha`, as we expect such a linear model to under-fit</span>
<span class="comment"># on such a large dataset.</span>

<span class="keyword">from</span> <span class="identifier">sklearn</span><span class="punctuation">.</span><span class="identifier">linear_model</span> <span class="keyword">import</span> <span class="identifier">Ridge</span>


<span class="identifier">ridge_glm</span> <span class="arithmetic-assignment">=</span> <span class="identifier">Pipeline</span><span class="grouping">(</span><span class="grouping">[</span>
    <span class="grouping">(</span><span class="string-literal">"preprocessor"</span><span class="punctuation">,</span> <span class="identifier">linear_model_preprocessor</span><span class="grouping">)</span><span class="punctuation">,</span>
    <span class="grouping">(</span><span class="string-literal">"regressor"</span><span class="punctuation">,</span> <span class="identifier">Ridge</span><span class="grouping">(</span><span class="identifier">alpha</span><span class="arithmetic-assignment">=</span><span class="float-literal">1e-6</span><span class="grouping">)</span><span class="grouping">)</span><span class="punctuation">,</span>
<span class="grouping">]</span><span class="grouping">)</span><span class="punctuation">.</span><span class="identifier">fit</span><span class="grouping">(</span><span class="identifier">df_train</span><span class="punctuation">,</span> <span class="identifier">df_train</span><span class="grouping">[</span><span class="string-literal">"Frequency"</span><span class="grouping">]</span><span class="punctuation">,</span>
       <span class="identifier">regressor__sample_weight</span><span class="arithmetic-assignment">=</span><span class="identifier">df_train</span><span class="grouping">[</span><span class="string-literal">"Exposure"</span><span class="grouping">]</span><span class="grouping">)</span>

<span class="comment"># %%</span>
<span class="comment"># The Poisson deviance cannot be computed on non-positive values predicted by</span>
<span class="comment"># the model. For models that do return a few non-positive predictions (e.g.</span>
<span class="comment"># :class:`~sklearn.linear_model.Ridge`) we ignore the corresponding samples,</span>
<span class="comment"># meaning that the obtained Poisson deviance is approximate. An alternative</span>
<span class="comment"># approach could be to use :class:`~sklearn.compose.TransformedTargetRegressor`</span>
<span class="comment"># meta-estimator to map ``y_pred`` to a strictly positive domain.</span>

<span class="identifier">print</span><span class="grouping">(</span><span class="string-literal">"Ridge evaluation:"</span><span class="grouping">)</span>
<span class="identifier">score_estimator</span><span class="grouping">(</span><span class="identifier">ridge_glm</span><span class="punctuation">,</span> <span class="identifier">df_test</span><span class="grouping">)</span>

<span class="comment"># %%</span>
<span class="comment"># Next we fit the Poisson regressor on the target variable. We set the</span>
<span class="comment"># regularization strength ``alpha`` to approximately 1e-6 over number of</span>
<span class="comment"># samples (i.e. `1e-12`) in order to mimic the Ridge regressor whose L2 penalty</span>
<span class="comment"># term scales differently with the number of samples.</span>
<span class="comment">#</span>
<span class="comment"># Since the Poisson regressor internally models the log of the expected target</span>
<span class="comment"># value instead of the expected value directly (log vs identity link function),</span>
<span class="comment"># the relationship between X and y is not exactly linear anymore. Therefore the</span>
<span class="comment"># Poisson regressor is called a Generalized Linear Model (GLM) rather than a</span>
<span class="comment"># vanilla linear model as is the case for Ridge regression.</span>

<span class="keyword">from</span> <span class="identifier">sklearn</span><span class="punctuation">.</span><span class="identifier">linear_model</span> <span class="keyword">import</span> <span class="identifier">PoissonRegressor</span>

<span class="identifier">n_samples</span> <span class="arithmetic-assignment">=</span> <span class="identifier">df_train</span><span class="punctuation">.</span><span class="identifier">shape</span><span class="grouping">[</span><span class="int-literal">0</span><span class="grouping">]</span>

<span class="identifier">poisson_glm</span> <span class="arithmetic-assignment">=</span> <span class="identifier">Pipeline</span><span class="grouping">(</span><span class="grouping">[</span>
    <span class="grouping">(</span><span class="string-literal">"preprocessor"</span><span class="punctuation">,</span> <span class="identifier">linear_model_preprocessor</span><span class="grouping">)</span><span class="punctuation">,</span>
    <span class="grouping">(</span><span class="string-literal">"regressor"</span><span class="punctuation">,</span> <span class="identifier">PoissonRegressor</span><span class="grouping">(</span><span class="identifier">alpha</span><span class="arithmetic-assignment">=</span><span class="float-literal">1e-12</span><span class="punctuation">,</span> <span class="identifier">max_iter</span><span class="arithmetic-assignment">=</span><span class="int-literal">300</span><span class="grouping">)</span><span class="grouping">)</span>
<span class="grouping">]</span><span class="grouping">)</span>
<span class="identifier">poisson_glm</span><span class="punctuation">.</span><span class="identifier">fit</span><span class="grouping">(</span><span class="identifier">df_train</span><span class="punctuation">,</span> <span class="identifier">df_train</span><span class="grouping">[</span><span class="string-literal">"Frequency"</span><span class="grouping">]</span><span class="punctuation">,</span>
                <span class="identifier">regressor__sample_weight</span><span class="arithmetic-assignment">=</span><span class="identifier">df_train</span><span class="grouping">[</span><span class="string-literal">"Exposure"</span><span class="grouping">]</span><span class="grouping">)</span>

<span class="identifier">print</span><span class="grouping">(</span><span class="string-literal">"PoissonRegressor evaluation:"</span><span class="grouping">)</span>
<span class="identifier">score_estimator</span><span class="grouping">(</span><span class="identifier">poisson_glm</span><span class="punctuation">,</span> <span class="identifier">df_test</span><span class="grouping">)</span>

<span class="comment"># %%</span>
<span class="comment"># Gradient Boosting Regression Trees for Poisson regression</span>
<span class="comment"># ---------------------------------------------------------</span>
<span class="comment">#</span>
<span class="comment"># Finally, we will consider a non-linear model, namely Gradient Boosting</span>
<span class="comment"># Regression Trees. Tree-based models do not require the categorical data to be</span>
<span class="comment"># one-hot encoded: instead, we can encode each category label with an arbitrary</span>
<span class="comment"># integer using :class:`~sklearn.preprocessing.OrdinalEncoder`. With this</span>
<span class="comment"># encoding, the trees will treat the categorical features as ordered features,</span>
<span class="comment"># which might not be always a desired behavior. However this effect is limited</span>
<span class="comment"># for deep enough trees which are able to recover the categorical nature of the</span>
<span class="comment"># features. The main advantage of the</span>
<span class="comment"># :class:`~sklearn.preprocessing.OrdinalEncoder` over the</span>
<span class="comment"># :class:`~sklearn.preprocessing.OneHotEncoder` is that it will make training</span>
<span class="comment"># faster.</span>
<span class="comment">#</span>
<span class="comment"># Gradient Boosting also gives the possibility to fit the trees with a Poisson</span>
<span class="comment"># loss (with an implicit log-link function) instead of the default</span>
<span class="comment"># least-squares loss. Here we only fit trees with the Poisson loss to keep this</span>
<span class="comment"># example concise.</span>

<span class="keyword">from</span> <span class="identifier">sklearn</span><span class="punctuation">.</span><span class="identifier">ensemble</span> <span class="keyword">import</span> <span class="identifier">HistGradientBoostingRegressor</span>
<span class="keyword">from</span> <span class="identifier">sklearn</span><span class="punctuation">.</span><span class="identifier">preprocessing</span> <span class="keyword">import</span> <span class="identifier">OrdinalEncoder</span>


<span class="identifier">tree_preprocessor</span> <span class="arithmetic-assignment">=</span> <span class="identifier">ColumnTransformer</span><span class="grouping">(</span>
    <span class="grouping">[</span>
        <span class="grouping">(</span><span class="string-literal">"categorical"</span><span class="punctuation">,</span> <span class="identifier">OrdinalEncoder</span><span class="grouping">(</span><span class="grouping">)</span><span class="punctuation">,</span>
            <span class="grouping">[</span><span class="string-literal">"VehBrand", "VehPower", "VehGas", "Region", "Area"</span><span class="grouping">]</span><span class="grouping">)</span><span class="punctuation">,</span>
        <span class="grouping">(</span><span class="string-literal">"numeric", "passthrough"</span><span class="punctuation">,</span>
            <span class="grouping">[</span><span class="string-literal">"VehAge", "DrivAge", "BonusMalus", "Density"</span><span class="grouping">]</span><span class="grouping">)</span><span class="punctuation">,</span>
    <span class="grouping">]</span><span class="punctuation">,</span>
    <span class="identifier">remainder</span><span class="arithmetic-assignment">=</span><span class="string-literal">"drop"</span><span class="punctuation">,</span>
<span class="grouping">)</span>
<span class="identifier">poisson_gbrt</span> <span class="arithmetic-assignment">=</span> <span class="identifier">Pipeline</span><span class="grouping">(</span><span class="grouping">[</span>
    <span class="grouping">(</span><span class="string-literal">"preprocessor"</span><span class="punctuation">,</span> <span class="identifier">tree_preprocessor</span><span class="grouping">)</span><span class="punctuation">,</span>
    <span class="grouping">(</span><span class="string-literal">"regressor", HistGradientBoostingRegressor(loss="poisson"</span><span class="punctuation">,</span>
                                                <span class="identifier">max_leaf_nodes</span><span class="arithmetic-assignment">=</span><span class="int-literal">128</span><span class="grouping">)</span><span class="grouping">)</span><span class="punctuation">,</span>
<span class="grouping">]</span><span class="grouping">)</span>
<span class="identifier">poisson_gbrt</span><span class="punctuation">.</span><span class="identifier">fit</span><span class="grouping">(</span><span class="identifier">df_train</span><span class="punctuation">,</span> <span class="identifier">df_train</span><span class="grouping">[</span><span class="string-literal">"Frequency"</span><span class="grouping">]</span><span class="punctuation">,</span>
                 <span class="identifier">regressor__sample_weight</span><span class="arithmetic-assignment">=</span><span class="identifier">df_train</span><span class="grouping">[</span><span class="string-literal">"Exposure"</span><span class="grouping">]</span><span class="grouping">)</span>

<span class="identifier">print</span><span class="grouping">(</span><span class="string-literal">"Poisson Gradient Boosted Trees evaluation:"</span><span class="grouping">)</span>
<span class="identifier">score_estimator</span><span class="grouping">(</span><span class="identifier">poisson_gbrt</span><span class="punctuation">,</span> <span class="identifier">df_test</span><span class="grouping">)</span>

<span class="comment"># %%</span>
<span class="comment"># Like the Poisson GLM above, the gradient boosted trees model minimizes</span>
<span class="comment"># the Poisson deviance. However, because of a higher predictive power,</span>
<span class="comment"># it reaches lower values of Poisson deviance.</span>
<span class="comment">#</span>
<span class="comment"># Evaluating models with a single train / test split is prone to random</span>
<span class="comment"># fluctuations. If computing resources allow, it should be verified that</span>
<span class="comment"># cross-validated performance metrics would lead to similar conclusions.</span>
<span class="comment">#</span>
<span class="comment"># The qualitative difference between these models can also be visualized by</span>
<span class="comment"># comparing the histogram of observed target values with that of predicted</span>
<span class="comment"># values:</span>

<span class="identifier">fig</span><span class="punctuation">,</span> <span class="identifier">axes</span> <span class="arithmetic-assignment">=</span> <span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">subplots</span><span class="grouping">(</span><span class="identifier">nrows</span><span class="arithmetic-assignment">=</span><span class="int-literal">2</span><span class="punctuation">,</span> <span class="identifier">ncols</span><span class="arithmetic-assignment">=</span><span class="int-literal">4</span><span class="punctuation">,</span> <span class="identifier">figsize</span><span class="arithmetic-assignment">=</span><span class="grouping">(</span><span class="int-literal">16</span><span class="punctuation">,</span> <span class="int-literal">6</span><span class="grouping">)</span><span class="punctuation">,</span> <span class="identifier">sharey</span><span class="arithmetic-assignment">=</span><span class="bool-literal">True</span><span class="grouping">)</span>
<span class="identifier">fig</span><span class="punctuation">.</span><span class="identifier">subplots_adjust</span><span class="grouping">(</span><span class="identifier">bottom</span><span class="arithmetic-assignment">=</span><span class="float-literal">0.2</span><span class="grouping">)</span>
<span class="identifier">n_bins</span> <span class="arithmetic-assignment">=</span> <span class="int-literal">20</span>
<span class="keyword">for</span> <span class="identifier">row_idx</span><span class="punctuation">,</span> <span class="identifier">label</span><span class="punctuation">,</span> <span class="identifier">df</span> <span class="relational-operator">in</span> <span class="identifier">zip</span><span class="grouping">(</span><span class="identifier">range</span><span class="grouping">(</span><span class="int-literal">2</span><span class="grouping">)</span><span class="punctuation">,</span>
                              <span class="grouping">[</span><span class="string-literal">"train", "test"</span><span class="grouping">]</span><span class="punctuation">,</span>
                              <span class="grouping">[</span><span class="identifier">df_train</span><span class="punctuation">,</span> <span class="identifier">df_test</span><span class="grouping">]</span><span class="grouping">)</span><span class="punctuation">:</span>
    <span class="identifier">df</span><span class="grouping">[</span><span class="string-literal">"Frequency"</span><span class="grouping">]</span><span class="punctuation">.</span><span class="identifier">hist</span><span class="grouping">(</span><span class="identifier">bins</span><span class="arithmetic-assignment">=</span><span class="identifier">np</span><span class="punctuation">.</span><span class="identifier">linspace</span><span class="grouping">(</span><span class="arithmetic-operator">-</span><span class="int-literal">1</span><span class="punctuation">,</span> <span class="int-literal">30</span><span class="punctuation">,</span> <span class="identifier">n_bins</span><span class="grouping">)</span><span class="punctuation">,</span>
                         <span class="identifier">ax</span><span class="arithmetic-assignment">=</span><span class="identifier">axes</span><span class="grouping">[</span><span class="identifier">row_idx</span><span class="punctuation">,</span> <span class="int-literal">0</span><span class="grouping">]</span><span class="grouping">)</span>

    <span class="identifier">axes</span><span class="grouping">[</span><span class="identifier">row_idx</span><span class="punctuation">,</span> <span class="int-literal">0</span><span class="grouping">]</span><span class="punctuation">.</span><span class="identifier">set_title</span><span class="grouping">(</span><span class="string-literal">"Data"</span><span class="grouping">)</span>
    <span class="identifier">axes</span><span class="grouping">[</span><span class="identifier">row_idx</span><span class="punctuation">,</span> <span class="int-literal">0</span><span class="grouping">]</span><span class="punctuation">.</span><span class="identifier">set_yscale</span><span class="grouping">(</span><span class="string-literal">'log'</span><span class="grouping">)</span>
    <span class="identifier">axes</span><span class="grouping">[</span><span class="identifier">row_idx</span><span class="punctuation">,</span> <span class="int-literal">0</span><span class="grouping">]</span><span class="punctuation">.</span><span class="identifier">set_xlabel</span><span class="grouping">(</span><span class="string-literal">"y (observed Frequency)"</span><span class="grouping">)</span>
    <span class="identifier">axes</span><span class="grouping">[</span><span class="identifier">row_idx</span><span class="punctuation">,</span> <span class="int-literal">0</span><span class="grouping">]</span><span class="punctuation">.</span><span class="identifier">set_ylim</span><span class="grouping">(</span><span class="grouping">[</span><span class="float-literal">1e1</span><span class="punctuation">,</span> <span class="float-literal">5e5</span><span class="grouping">]</span><span class="grouping">)</span>
    <span class="identifier">axes</span><span class="grouping">[</span><span class="identifier">row_idx</span><span class="punctuation">,</span> <span class="int-literal">0</span><span class="grouping">]</span><span class="punctuation">.</span><span class="identifier">set_ylabel</span><span class="grouping">(</span><span class="identifier">label</span> <span class="arithmetic-operator">+</span> <span class="string-literal">" samples"</span><span class="grouping">)</span>

    <span class="keyword">for</span> <span class="identifier">idx</span><span class="punctuation">,</span> <span class="identifier">model</span> <span class="relational-operator">in</span> <span class="identifier">enumerate</span><span class="grouping">(</span><span class="grouping">[</span><span class="identifier">ridge_glm</span><span class="punctuation">,</span> <span class="identifier">poisson_glm</span><span class="punctuation">,</span> <span class="identifier">poisson_gbrt</span><span class="grouping">]</span><span class="grouping">)</span><span class="punctuation">:</span>
        <span class="identifier">y_pred</span> <span class="arithmetic-assignment">=</span> <span class="identifier">model</span><span class="punctuation">.</span><span class="identifier">predict</span><span class="grouping">(</span><span class="identifier">df</span><span class="grouping">)</span>

        <span class="identifier">pd</span><span class="punctuation">.</span><span class="identifier">Series</span><span class="grouping">(</span><span class="identifier">y_pred</span><span class="grouping">)</span><span class="punctuation">.</span><span class="identifier">hist</span><span class="grouping">(</span><span class="identifier">bins</span><span class="arithmetic-assignment">=</span><span class="identifier">np</span><span class="punctuation">.</span><span class="identifier">linspace</span><span class="grouping">(</span><span class="arithmetic-operator">-</span><span class="int-literal">1</span><span class="punctuation">,</span> <span class="int-literal">4</span><span class="punctuation">,</span> <span class="identifier">n_bins</span><span class="grouping">)</span><span class="punctuation">,</span>
                               <span class="identifier">ax</span><span class="arithmetic-assignment">=</span><span class="identifier">axes</span><span class="grouping">[</span><span class="identifier">row_idx</span><span class="punctuation">,</span> <span class="identifier">idx</span><span class="arithmetic-operator">+</span><span class="int-literal">1</span><span class="grouping">]</span><span class="grouping">)</span>
        <span class="identifier">axes</span><span class="grouping">[</span><span class="identifier">row_idx</span><span class="punctuation">,</span> <span class="identifier">idx</span> <span class="arithmetic-operator">+</span> <span class="int-literal">1</span><span class="grouping">]</span><span class="punctuation">.</span><span class="identifier">set</span><span class="grouping">(</span>
            <span class="identifier">title</span><span class="arithmetic-assignment">=</span><span class="identifier">model</span><span class="grouping">[</span><span class="arithmetic-operator">-</span><span class="int-literal">1</span><span class="grouping">]</span><span class="punctuation">.</span><span class="identifier">__class__</span><span class="punctuation">.</span><span class="identifier">__name__</span><span class="punctuation">,</span>
            <span class="identifier">yscale</span><span class="arithmetic-assignment">=</span><span class="string-literal">'log'</span><span class="punctuation">,</span>
            <span class="identifier">xlabel</span><span class="arithmetic-assignment">=</span><span class="string-literal">"y_pred (predicted expected Frequency)"</span>
        <span class="grouping">)</span>
<span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">tight_layout</span><span class="grouping">(</span><span class="grouping">)</span>

<span class="comment"># %%</span>
<span class="comment"># The experimental data presents a long tail distribution for ``y``. In all</span>
<span class="comment"># models, we predict the expected frequency of a random variable, so we will</span>
<span class="comment"># have necessarily fewer extreme values than for the observed realizations of</span>
<span class="comment"># that random variable. This explains that the mode of the histograms of model</span>
<span class="comment"># predictions doesn't necessarily correspond to the smallest value.</span>
<span class="comment"># Additionally, the normal distribution used in ``Ridge`` has a constant</span>
<span class="comment"># variance, while for the Poisson distribution used in ``PoissonRegressor`` and</span>
<span class="comment"># ``HistGradientBoostingRegressor``, the variance is proportional to the</span>
<span class="comment"># predicted expected value.</span>
<span class="comment">#</span>
<span class="comment"># Thus, among the considered estimators, ``PoissonRegressor`` and</span>
<span class="comment"># ``HistGradientBoostingRegressor`` are a-priori better suited for modeling the</span>
<span class="comment"># long tail distribution of the non-negative data as compared to the ``Ridge``</span>
<span class="comment"># model which makes a wrong assumption on the distribution of the target</span>
<span class="comment"># variable.</span>
<span class="comment">#</span>
<span class="comment"># The ``HistGradientBoostingRegressor`` estimator has the most flexibility and</span>
<span class="comment"># is able to predict higher expected values.</span>
<span class="comment">#</span>
<span class="comment"># Note that we could have used the least squares loss for the</span>
<span class="comment"># ``HistGradientBoostingRegressor`` model. This would wrongly assume a normal</span>
<span class="comment"># distributed response variable as does the `Ridge` model, and possibly</span>
<span class="comment"># also lead to slightly negative predictions. However the gradient boosted</span>
<span class="comment"># trees would still perform relatively well and in particular better than</span>
<span class="comment"># ``PoissonRegressor`` thanks to the flexibility of the trees combined with the</span>
<span class="comment"># large number of training samples.</span>
<span class="comment">#</span>
<span class="comment"># Evaluation of the calibration of predictions</span>
<span class="comment"># --------------------------------------------</span>
<span class="comment">#</span>
<span class="comment"># To ensure that estimators yield reasonable predictions for different</span>
<span class="comment"># policyholder types, we can bin test samples according to ``y_pred`` returned</span>
<span class="comment"># by each model. Then for each bin, we compare the mean predicted ``y_pred``,</span>
<span class="comment"># with the mean observed target:</span>

<span class="keyword">from</span> <span class="identifier">sklearn</span><span class="punctuation">.</span><span class="identifier">utils</span> <span class="keyword">import</span> <span class="identifier">gen_even_slices</span>


<span class="keyword">def</span> <span class="identifier">_mean_frequency_by_risk_group</span><span class="grouping">(</span><span class="identifier">y_true</span><span class="punctuation">,</span> <span class="identifier">y_pred</span><span class="punctuation">,</span> <span class="identifier">sample_weight</span><span class="arithmetic-assignment">=</span><span class="none-literal">None</span><span class="punctuation">,</span>
                                  <span class="identifier">n_bins</span><span class="arithmetic-assignment">=</span><span class="int-literal">100</span><span class="grouping">)</span><span class="punctuation">:</span>
    <span class="comment">"""Compare predictions and observations for bins ordered by y_pred.

    We order the samples by ``y_pred`` and split it in bins.
    In each bin the observed mean is compared with the predicted mean.

    Parameters
    ----------
    y_true: array-like of shape (n_samples,)
        Ground truth (correct) target values.
    y_pred: array-like of shape (n_samples,)
        Estimated target values.
    sample_weight : array-like of shape (n_samples,)
        Sample weights.
    n_bins: int
        Number of bins to use.

    Returns
    -------
    bin_centers: ndarray of shape (n_bins,)
        bin centers
    y_true_bin: ndarray of shape (n_bins,)
        average y_pred for each bin
    y_pred_bin: ndarray of shape (n_bins,)
        average y_pred for each bin
    """</span>
    <span class="identifier">idx_sort</span> <span class="arithmetic-assignment">=</span> <span class="identifier">np</span><span class="punctuation">.</span><span class="identifier">argsort</span><span class="grouping">(</span><span class="identifier">y_pred</span><span class="grouping">)</span>
    <span class="identifier">bin_centers</span> <span class="arithmetic-assignment">=</span> <span class="identifier">np</span><span class="punctuation">.</span><span class="identifier">arange</span><span class="grouping">(</span><span class="int-literal">0</span><span class="punctuation">,</span> <span class="int-literal">1</span><span class="punctuation">,</span> <span class="int-literal">1</span><span class="arithmetic-operator">/</span><span class="identifier">n_bins</span><span class="grouping">)</span> <span class="arithmetic-operator">+</span> <span class="float-literal">0.5</span><span class="arithmetic-operator">/</span><span class="identifier">n_bins</span>
    <span class="identifier">y_pred_bin</span> <span class="arithmetic-assignment">=</span> <span class="identifier">np</span><span class="punctuation">.</span><span class="identifier">zeros</span><span class="grouping">(</span><span class="identifier">n_bins</span><span class="grouping">)</span>
    <span class="identifier">y_true_bin</span> <span class="arithmetic-assignment">=</span> <span class="identifier">np</span><span class="punctuation">.</span><span class="identifier">zeros</span><span class="grouping">(</span><span class="identifier">n_bins</span><span class="grouping">)</span>

    <span class="keyword">for</span> <span class="identifier">n</span><span class="punctuation">,</span> <span class="identifier">sl</span> <span class="relational-operator">in</span> <span class="identifier">enumerate</span><span class="grouping">(</span><span class="identifier">gen_even_slices</span><span class="grouping">(</span><span class="identifier">len</span><span class="grouping">(</span><span class="identifier">y_true</span><span class="grouping">)</span><span class="punctuation">,</span> <span class="identifier">n_bins</span><span class="grouping">)</span><span class="grouping">)</span><span class="punctuation">:</span>
        <span class="identifier">weights</span> <span class="arithmetic-assignment">=</span> <span class="identifier">sample_weight</span><span class="grouping">[</span><span class="identifier">idx_sort</span><span class="grouping">]</span><span class="grouping">[</span><span class="identifier">sl</span><span class="grouping">]</span>
        <span class="identifier">y_pred_bin</span><span class="grouping">[</span><span class="identifier">n</span><span class="grouping">]</span> <span class="arithmetic-assignment">=</span> <span class="identifier">np</span><span class="punctuation">.</span><span class="identifier">average</span><span class="grouping">(</span>
            <span class="identifier">y_pred</span><span class="grouping">[</span><span class="identifier">idx_sort</span><span class="grouping">]</span><span class="grouping">[</span><span class="identifier">sl</span><span class="grouping">]</span><span class="punctuation">,</span> <span class="identifier">weights</span><span class="arithmetic-assignment">=</span><span class="identifier">weights</span>
        <span class="grouping">)</span>
        <span class="identifier">y_true_bin</span><span class="grouping">[</span><span class="identifier">n</span><span class="grouping">]</span> <span class="arithmetic-assignment">=</span> <span class="identifier">np</span><span class="punctuation">.</span><span class="identifier">average</span><span class="grouping">(</span>
            <span class="identifier">y_true</span><span class="grouping">[</span><span class="identifier">idx_sort</span><span class="grouping">]</span><span class="grouping">[</span><span class="identifier">sl</span><span class="grouping">]</span><span class="punctuation">,</span>
            <span class="identifier">weights</span><span class="arithmetic-assignment">=</span><span class="identifier">weights</span>
        <span class="grouping">)</span>
    <span class="keyword">return</span> <span class="identifier">bin_centers</span><span class="punctuation">,</span> <span class="identifier">y_true_bin</span><span class="punctuation">,</span> <span class="identifier">y_pred_bin</span>


<span class="identifier">print</span><span class="grouping">(</span><span class="identifier">f</span><span class="string-literal">"Actual number of claims: {df_test['ClaimNb'].sum()}"</span><span class="grouping">)</span>
<span class="identifier">fig</span><span class="punctuation">,</span> <span class="identifier">ax</span> <span class="arithmetic-assignment">=</span> <span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">subplots</span><span class="grouping">(</span><span class="identifier">nrows</span><span class="arithmetic-assignment">=</span><span class="int-literal">2</span><span class="punctuation">,</span> <span class="identifier">ncols</span><span class="arithmetic-assignment">=</span><span class="int-literal">2</span><span class="punctuation">,</span> <span class="identifier">figsize</span><span class="arithmetic-assignment">=</span><span class="grouping">(</span><span class="int-literal">12</span><span class="punctuation">,</span> <span class="int-literal">8</span><span class="grouping">)</span><span class="grouping">)</span>
<span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">subplots_adjust</span><span class="grouping">(</span><span class="identifier">wspace</span><span class="arithmetic-assignment">=</span><span class="float-literal">0.3</span><span class="grouping">)</span>

<span class="keyword">for</span> <span class="identifier">axi</span><span class="punctuation">,</span> <span class="identifier">model</span> <span class="relational-operator">in</span> <span class="identifier">zip</span><span class="grouping">(</span><span class="identifier">ax</span><span class="punctuation">.</span><span class="identifier">ravel</span><span class="grouping">(</span><span class="grouping">)</span><span class="punctuation">,</span> <span class="grouping">[</span><span class="identifier">ridge_glm</span><span class="punctuation">,</span> <span class="identifier">poisson_glm</span><span class="punctuation">,</span> <span class="identifier">poisson_gbrt</span><span class="punctuation">,</span>
                                   <span class="identifier">dummy</span><span class="grouping">]</span><span class="grouping">)</span><span class="punctuation">:</span>
    <span class="identifier">y_pred</span> <span class="arithmetic-assignment">=</span> <span class="identifier">model</span><span class="punctuation">.</span><span class="identifier">predict</span><span class="grouping">(</span><span class="identifier">df_test</span><span class="grouping">)</span>
    <span class="identifier">y_true</span> <span class="arithmetic-assignment">=</span> <span class="identifier">df_test</span><span class="grouping">[</span><span class="string-literal">"Frequency"</span><span class="grouping">]</span><span class="punctuation">.</span><span class="identifier">values</span>
    <span class="identifier">exposure</span> <span class="arithmetic-assignment">=</span> <span class="identifier">df_test</span><span class="grouping">[</span><span class="string-literal">"Exposure"</span><span class="grouping">]</span><span class="punctuation">.</span><span class="identifier">values</span>
    <span class="identifier">q</span><span class="punctuation">,</span> <span class="identifier">y_true_seg</span><span class="punctuation">,</span> <span class="identifier">y_pred_seg</span> <span class="arithmetic-assignment">=</span> <span class="identifier">_mean_frequency_by_risk_group</span><span class="grouping">(</span>
        <span class="identifier">y_true</span><span class="punctuation">,</span> <span class="identifier">y_pred</span><span class="punctuation">,</span> <span class="identifier">sample_weight</span><span class="arithmetic-assignment">=</span><span class="identifier">exposure</span><span class="punctuation">,</span> <span class="identifier">n_bins</span><span class="arithmetic-assignment">=</span><span class="int-literal">10</span><span class="grouping">)</span>

    <span class="comment"># Name of the model after the estimator used in the last step of the</span>
    <span class="comment"># pipeline.</span>
    <span class="identifier">print</span><span class="grouping">(</span><span class="identifier">f</span><span class="string-literal">"Predicted number of claims by {model[-1]}: "</span>
          <span class="identifier">f</span><span class="string-literal">"{np.sum(y_pred * exposure):.1f}"</span><span class="grouping">)</span>

    <span class="identifier">axi</span><span class="punctuation">.</span><span class="identifier">plot</span><span class="grouping">(</span><span class="identifier">q</span><span class="punctuation">,</span> <span class="identifier">y_pred_seg</span><span class="punctuation">,</span> <span class="identifier">marker</span><span class="arithmetic-assignment">=</span><span class="string-literal">'x'</span><span class="punctuation">,</span> <span class="identifier">linestyle</span><span class="arithmetic-assignment">=</span><span class="string-literal">"--", label="predictions"</span><span class="grouping">)</span>
    <span class="identifier">axi</span><span class="punctuation">.</span><span class="identifier">plot</span><span class="grouping">(</span><span class="identifier">q</span><span class="punctuation">,</span> <span class="identifier">y_true_seg</span><span class="punctuation">,</span> <span class="identifier">marker</span><span class="arithmetic-assignment">=</span><span class="string-literal">'o'</span><span class="punctuation">,</span> <span class="identifier">linestyle</span><span class="arithmetic-assignment">=</span><span class="string-literal">"--", label="observations"</span><span class="grouping">)</span>
    <span class="identifier">axi</span><span class="punctuation">.</span><span class="identifier">set_xlim</span><span class="grouping">(</span><span class="int-literal">0</span><span class="punctuation">,</span> <span class="float-literal">1.0</span><span class="grouping">)</span>
    <span class="identifier">axi</span><span class="punctuation">.</span><span class="identifier">set_ylim</span><span class="grouping">(</span><span class="int-literal">0</span><span class="punctuation">,</span> <span class="float-literal">0.5</span><span class="grouping">)</span>
    <span class="identifier">axi</span><span class="punctuation">.</span><span class="identifier">set</span><span class="grouping">(</span>
        <span class="identifier">title</span><span class="arithmetic-assignment">=</span><span class="identifier">model</span><span class="grouping">[</span><span class="arithmetic-operator">-</span><span class="int-literal">1</span><span class="grouping">]</span><span class="punctuation">,</span>
        <span class="identifier">xlabel</span><span class="arithmetic-assignment">=</span><span class="string-literal">'Fraction of samples sorted by y_pred'</span><span class="punctuation">,</span>
        <span class="identifier">ylabel</span><span class="arithmetic-assignment">=</span><span class="string-literal">'Mean Frequency (y_pred)'</span>
    <span class="grouping">)</span>
    <span class="identifier">axi</span><span class="punctuation">.</span><span class="identifier">legend</span><span class="grouping">(</span><span class="grouping">)</span>
<span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">tight_layout</span><span class="grouping">(</span><span class="grouping">)</span>

<span class="comment"># %%</span>
<span class="comment"># The dummy regression model predicts a constant frequency. This model does not</span>
<span class="comment"># attribute the same tied rank to all samples but is none-the-less globally</span>
<span class="comment"># well calibrated (to estimate the mean frequency of the entire population).</span>
<span class="comment">#</span>
<span class="comment"># The ``Ridge`` regression model can predict very low expected frequencies that</span>
<span class="comment"># do not match the data. It can therefore severly under-estimate the risk for</span>
<span class="comment"># some policyholders.</span>
<span class="comment">#</span>
<span class="comment"># ``PoissonRegressor`` and ``HistGradientBoostingRegressor`` show better</span>
<span class="comment"># consistency between predicted and observed targets, especially for low</span>
<span class="comment"># predicted target values.</span>
<span class="comment">#</span>
<span class="comment"># The sum of all predictions also confirms the calibration issue of the</span>
<span class="comment"># ``Ridge`` model: it under-estimates by more than 3% the total number of</span>
<span class="comment"># claims in the test set while the other three models can approximately recover</span>
<span class="comment"># the total number of claims of the test portfolio.</span>
<span class="comment">#</span>
<span class="comment"># Evaluation of the ranking power</span>
<span class="comment"># -------------------------------</span>
<span class="comment">#</span>
<span class="comment"># For some business applications, we are interested in the ability of the model</span>
<span class="comment"># to rank the riskiest from the safest policyholders, irrespective of the</span>
<span class="comment"># absolute value of the prediction. In this case, the model evaluation would</span>
<span class="comment"># cast the problem as a ranking problem rather than a regression problem.</span>
<span class="comment">#</span>
<span class="comment"># To compare the 3 models from this perspective, one can plot the cumulative</span>
<span class="comment"># proportion of claims vs the cumulative proportion of exposure for the test</span>
<span class="comment"># samples order by the model predictions, from safest to riskiest according to</span>
<span class="comment"># each model.</span>
<span class="comment">#</span>
<span class="comment"># This plot is called a Lorenz curve and can be summarized by the Gini index:</span>

<span class="keyword">from</span> <span class="identifier">sklearn</span><span class="punctuation">.</span><span class="identifier">metrics</span> <span class="keyword">import</span> <span class="identifier">auc</span>


<span class="keyword">def</span> <span class="identifier">lorenz_curve</span><span class="grouping">(</span><span class="identifier">y_true</span><span class="punctuation">,</span> <span class="identifier">y_pred</span><span class="punctuation">,</span> <span class="identifier">exposure</span><span class="grouping">)</span><span class="punctuation">:</span>
    <span class="identifier">y_true</span><span class="punctuation">,</span> <span class="identifier">y_pred</span> <span class="arithmetic-assignment">=</span> <span class="identifier">np</span><span class="punctuation">.</span><span class="invalid">a</span><span class="invalid">s</span><span class="invalid">a</span><span class="invalid">r</span><span class="invalid">r</span><span class="invalid">a</span><span class="invalid">y</span><span class="grouping">(</span><span class="identifier">y_true</span><span class="grouping">)</span><span class="punctuation">,</span> <span class="identifier">np</span><span class="punctuation">.</span><span class="invalid">a</span><span class="invalid">s</span><span class="invalid">a</span><span class="invalid">r</span><span class="invalid">r</span><span class="invalid">a</span><span class="invalid">y</span><span class="grouping">(</span><span class="identifier">y_pred</span><span class="grouping">)</span>
    <span class="identifier">exposure</span> <span class="arithmetic-assignment">=</span> <span class="identifier">np</span><span class="punctuation">.</span><span class="invalid">a</span><span class="invalid">s</span><span class="invalid">a</span><span class="invalid">r</span><span class="invalid">r</span><span class="invalid">a</span><span class="invalid">y</span><span class="grouping">(</span><span class="identifier">exposure</span><span class="grouping">)</span>

    <span class="comment"># order samples by increasing predicted risk:</span>
    <span class="identifier">ranking</span> <span class="arithmetic-assignment">=</span> <span class="identifier">np</span><span class="punctuation">.</span><span class="identifier">argsort</span><span class="grouping">(</span><span class="identifier">y_pred</span><span class="grouping">)</span>
    <span class="identifier">ranked_frequencies</span> <span class="arithmetic-assignment">=</span> <span class="identifier">y_true</span><span class="grouping">[</span><span class="identifier">ranking</span><span class="grouping">]</span>
    <span class="identifier">ranked_exposure</span> <span class="arithmetic-assignment">=</span> <span class="identifier">exposure</span><span class="grouping">[</span><span class="identifier">ranking</span><span class="grouping">]</span>
    <span class="identifier">cumulated_claims</span> <span class="arithmetic-assignment">=</span> <span class="identifier">np</span><span class="punctuation">.</span><span class="identifier">cumsum</span><span class="grouping">(</span><span class="identifier">ranked_frequencies</span> <span class="arithmetic-operator">*</span> <span class="identifier">ranked_exposure</span><span class="grouping">)</span>
    <span class="identifier">cumulated_claims</span> <span class="arithmetic-assignment">/=</span> <span class="identifier">cumulated_claims</span><span class="grouping">[</span><span class="arithmetic-operator">-</span><span class="int-literal">1</span><span class="grouping">]</span>
    <span class="identifier">cumulated_exposure</span> <span class="arithmetic-assignment">=</span> <span class="identifier">np</span><span class="punctuation">.</span><span class="identifier">cumsum</span><span class="grouping">(</span><span class="identifier">ranked_exposure</span><span class="grouping">)</span>
    <span class="identifier">cumulated_exposure</span> <span class="arithmetic-assignment">/=</span> <span class="identifier">cumulated_exposure</span><span class="grouping">[</span><span class="arithmetic-operator">-</span><span class="int-literal">1</span><span class="grouping">]</span>
    <span class="keyword">return</span> <span class="identifier">cumulated_exposure</span><span class="punctuation">,</span> <span class="identifier">cumulated_claims</span>


<span class="identifier">fig</span><span class="punctuation">,</span> <span class="identifier">ax</span> <span class="arithmetic-assignment">=</span> <span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">subplots</span><span class="grouping">(</span><span class="identifier">figsize</span><span class="arithmetic-assignment">=</span><span class="grouping">(</span><span class="int-literal">8</span><span class="punctuation">,</span> <span class="int-literal">8</span><span class="grouping">)</span><span class="grouping">)</span>

<span class="keyword">for</span> <span class="identifier">model</span> <span class="relational-operator">in</span> <span class="grouping">[</span><span class="identifier">dummy</span><span class="punctuation">,</span> <span class="identifier">ridge_glm</span><span class="punctuation">,</span> <span class="identifier">poisson_glm</span><span class="punctuation">,</span> <span class="identifier">poisson_gbrt</span><span class="grouping">]</span><span class="punctuation">:</span>
    <span class="identifier">y_pred</span> <span class="arithmetic-assignment">=</span> <span class="identifier">model</span><span class="punctuation">.</span><span class="identifier">predict</span><span class="grouping">(</span><span class="identifier">df_test</span><span class="grouping">)</span>
    <span class="identifier">cum_exposure</span><span class="punctuation">,</span> <span class="identifier">cum_claims</span> <span class="arithmetic-assignment">=</span> <span class="identifier">lorenz_curve</span><span class="grouping">(</span><span class="identifier">df_test</span><span class="grouping">[</span><span class="string-literal">"Frequency"</span><span class="grouping">]</span><span class="punctuation">,</span> <span class="identifier">y_pred</span><span class="punctuation">,</span>
                                            <span class="identifier">df_test</span><span class="grouping">[</span><span class="string-literal">"Exposure"</span><span class="grouping">]</span><span class="grouping">)</span>
    <span class="identifier">gini</span> <span class="arithmetic-assignment">=</span> <span class="int-literal">1</span> <span class="arithmetic-operator">-</span> <span class="int-literal">2</span> <span class="arithmetic-operator">*</span> <span class="identifier">auc</span><span class="grouping">(</span><span class="identifier">cum_exposure</span><span class="punctuation">,</span> <span class="identifier">cum_claims</span><span class="grouping">)</span>
    <span class="identifier">label</span> <span class="arithmetic-assignment">=</span> <span class="string-literal">"{} (Gini: {:.2f})"</span><span class="punctuation">.</span><span class="invalid">f</span><span class="invalid">o</span><span class="invalid">r</span><span class="invalid">m</span><span class="invalid">a</span><span class="invalid">t</span><span class="grouping">(</span><span class="identifier">model</span><span class="grouping">[</span><span class="arithmetic-operator">-</span><span class="int-literal">1</span><span class="grouping">]</span><span class="punctuation">,</span> <span class="identifier">gini</span><span class="grouping">)</span>
    <span class="identifier">ax</span><span class="punctuation">.</span><span class="identifier">plot</span><span class="grouping">(</span><span class="identifier">cum_exposure</span><span class="punctuation">,</span> <span class="identifier">cum_claims</span><span class="punctuation">,</span> <span class="identifier">linestyle</span><span class="arithmetic-assignment">=</span><span class="string-literal">"-"</span><span class="punctuation">,</span> <span class="identifier">label</span><span class="arithmetic-assignment">=</span><span class="identifier">label</span><span class="grouping">)</span>

<span class="comment"># Oracle model: y_pred == y_test</span>
<span class="identifier">cum_exposure</span><span class="punctuation">,</span> <span class="identifier">cum_claims</span> <span class="arithmetic-assignment">=</span> <span class="identifier">lorenz_curve</span><span class="grouping">(</span><span class="identifier">df_test</span><span class="grouping">[</span><span class="string-literal">"Frequency"</span><span class="grouping">]</span><span class="punctuation">,</span>
                                        <span class="identifier">df_test</span><span class="grouping">[</span><span class="string-literal">"Frequency"</span><span class="grouping">]</span><span class="punctuation">,</span>
                                        <span class="identifier">df_test</span><span class="grouping">[</span><span class="string-literal">"Exposure"</span><span class="grouping">]</span><span class="grouping">)</span>
<span class="identifier">gini</span> <span class="arithmetic-assignment">=</span> <span class="int-literal">1</span> <span class="arithmetic-operator">-</span> <span class="int-literal">2</span> <span class="arithmetic-operator">*</span> <span class="identifier">auc</span><span class="grouping">(</span><span class="identifier">cum_exposure</span><span class="punctuation">,</span> <span class="identifier">cum_claims</span><span class="grouping">)</span>
<span class="identifier">label</span> <span class="arithmetic-assignment">=</span> <span class="string-literal">"Oracle (Gini: {:.2f})"</span><span class="punctuation">.</span><span class="invalid">f</span><span class="invalid">o</span><span class="invalid">r</span><span class="invalid">m</span><span class="invalid">a</span><span class="invalid">t</span><span class="grouping">(</span><span class="identifier">gini</span><span class="grouping">)</span>
<span class="identifier">ax</span><span class="punctuation">.</span><span class="identifier">plot</span><span class="grouping">(</span><span class="identifier">cum_exposure</span><span class="punctuation">,</span> <span class="identifier">cum_claims</span><span class="punctuation">,</span> <span class="identifier">linestyle</span><span class="arithmetic-assignment">=</span><span class="string-literal">"-.", color="gray"</span><span class="punctuation">,</span> <span class="identifier">label</span><span class="arithmetic-assignment">=</span><span class="identifier">label</span><span class="grouping">)</span>

<span class="comment"># Random Baseline</span>
<span class="identifier">ax</span><span class="punctuation">.</span><span class="identifier">plot</span><span class="grouping">(</span><span class="grouping">[</span><span class="int-literal">0</span><span class="punctuation">,</span> <span class="int-literal">1</span><span class="grouping">]</span><span class="punctuation">,</span> <span class="grouping">[</span><span class="int-literal">0</span><span class="punctuation">,</span> <span class="int-literal">1</span><span class="grouping">]</span><span class="punctuation">,</span> <span class="identifier">linestyle</span><span class="arithmetic-assignment">=</span><span class="string-literal">"--", color="black"</span><span class="punctuation">,</span>
        <span class="identifier">label</span><span class="arithmetic-assignment">=</span><span class="string-literal">"Random baseline"</span><span class="grouping">)</span>
<span class="identifier">ax</span><span class="punctuation">.</span><span class="identifier">set</span><span class="grouping">(</span>
    <span class="identifier">title</span><span class="arithmetic-assignment">=</span><span class="string-literal">"Lorenz curves by model"</span><span class="punctuation">,</span>
    <span class="identifier">xlabel</span><span class="arithmetic-assignment">=</span><span class="string-literal">'Cumulative proportion of exposure (from safest to riskiest)'</span><span class="punctuation">,</span>
    <span class="identifier">ylabel</span><span class="arithmetic-assignment">=</span><span class="string-literal">'Cumulative proportion of claims'</span>
<span class="grouping">)</span>
<span class="identifier">ax</span><span class="punctuation">.</span><span class="identifier">legend</span><span class="grouping">(</span><span class="identifier">loc</span><span class="arithmetic-assignment">=</span><span class="string-literal">"upper left"</span><span class="grouping">)</span>

<span class="comment"># %%</span>
<span class="comment"># As expected, the dummy regressor is unable to correctly rank the samples and</span>
<span class="comment"># therefore performs the worst on this plot.</span>
<span class="comment">#</span>
<span class="comment"># The tree-based model is significantly better at ranking policyholders by risk</span>
<span class="comment"># while the two linear models perform similarly.</span>
<span class="comment">#</span>
<span class="comment"># All three models are significantly better than chance but also very far from</span>
<span class="comment"># making perfect predictions.</span>
<span class="comment">#</span>
<span class="comment"># This last point is expected due to the nature of the problem: the occurrence</span>
<span class="comment"># of accidents is mostly dominated by circumstantial causes that are not</span>
<span class="comment"># captured in the columns of the dataset and can indeed be considered as purely</span>
<span class="comment"># random.</span>
<span class="comment">#</span>
<span class="comment"># The linear models assume no interactions between the input variables which</span>
<span class="comment"># likely causes under-fitting. Inserting a polynomial feature extractor</span>
<span class="comment"># (:func:`~sklearn.preprocessing.PolynomialFeatures`) indeed increases their</span>
<span class="comment"># discrimative power by 2 points of Gini index. In particular it improves the</span>
<span class="comment"># ability of the models to identify the top 5% riskiest profiles.</span>
<span class="comment">#</span>
<span class="comment"># Main takeaways</span>
<span class="comment"># --------------</span>
<span class="comment">#</span>
<span class="comment"># - The performance of the models can be evaluated by their ability to yield</span>
<span class="comment">#   well-calibrated predictions and a good ranking.</span>
<span class="comment">#</span>
<span class="comment"># - The calibration of the model can be assessed by plotting the mean observed</span>
<span class="comment">#   value vs the mean predicted value on groups of test samples binned by</span>
<span class="comment">#   predicted risk.</span>
<span class="comment">#</span>
<span class="comment"># - The least squares loss (along with the implicit use of the identity link</span>
<span class="comment">#   function) of the Ridge regression model seems to cause this model to be</span>
<span class="comment">#   badly calibrated. In particular, it tends to underestimate the risk and can</span>
<span class="comment">#   even predict invalid negative frequencies.</span>
<span class="comment">#</span>
<span class="comment"># - Using the Poisson loss with a log-link can correct these problems and lead</span>
<span class="comment">#   to a well-calibrated linear model.</span>
<span class="comment">#</span>
<span class="comment"># - The Gini index reflects the ability of a model to rank predictions</span>
<span class="comment">#   irrespective of their absolute values, and therefore only assess their</span>
<span class="comment">#   ranking power.</span>
<span class="comment">#</span>
<span class="comment"># - Despite the improvement in calibration, the ranking power of both linear</span>
<span class="comment">#   models are comparable and well below the ranking power of the Gradient</span>
<span class="comment">#   Boosting Regression Trees.</span>
<span class="comment">#</span>
<span class="comment"># - The Poisson deviance computed as an evaluation metric reflects both the</span>
<span class="comment">#   calibration and the ranking power of the model. It also makes a linear</span>
<span class="comment">#   assumption on the ideal relationship between the expected value and the</span>
<span class="comment">#   variance of the response variable. For the sake of conciseness we did not</span>
<span class="comment">#   check whether this assumption holds.</span>
<span class="comment">#</span>
<span class="comment"># - Traditional regression metrics such as Mean Squared Error and Mean Absolute</span>
<span class="comment">#   Error are hard to meaningfully interpret on count values with many zeros.</span>

<span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">show</span><span class="grouping">(</span><span class="grouping">)</span>

    </pre>
  </body>
</html>
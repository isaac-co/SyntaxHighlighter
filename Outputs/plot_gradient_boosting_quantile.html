<html>
  <head>
    <title>Python Lexical Highliter</title>
    <link rel="stylesheet" href="token_colors.css">
  </head>
  <body>
    <pre><span class="comment">"""
=====================================================
Prediction Intervals for Gradient Boosting Regression
=====================================================

This example shows how quantile regression can be used to create prediction
intervals.
"""</span>
<span class="comment"># %%</span>
<span class="comment"># Generate some data for a synthetic regression problem by applying the</span>
<span class="comment"># function f to uniformly sampled random inputs.</span>
<span class="keyword">import</span> <span class="identifier">numpy</span> <span class="keyword">as</span> <span class="identifier">np</span>
<span class="keyword">from</span> <span class="identifier">sklearn</span><span class="punctuation">.</span><span class="identifier">model_selection</span> <span class="keyword">import</span> <span class="identifier">train_test_split</span>


<span class="keyword">def</span> <span class="identifier">f</span><span class="grouping">(</span><span class="identifier">x</span><span class="grouping">)</span><span class="punctuation">:</span>
    <span class="comment">"""The function to predict."""</span>
    <span class="keyword">return</span> <span class="identifier">x</span> <span class="arithmetic-operator">*</span> <span class="identifier">np</span><span class="punctuation">.</span><span class="identifier">sin</span><span class="grouping">(</span><span class="identifier">x</span><span class="grouping">)</span>


<span class="identifier">rng</span> <span class="arithmetic-assignment">=</span> <span class="identifier">np</span><span class="punctuation">.</span><span class="identifier">random</span><span class="punctuation">.</span><span class="identifier">RandomState</span><span class="grouping">(</span><span class="int-literal">42</span><span class="grouping">)</span>
<span class="identifier">X</span> <span class="arithmetic-assignment">=</span> <span class="identifier">np</span><span class="punctuation">.</span><span class="identifier">atleast_2d</span><span class="grouping">(</span><span class="identifier">rng</span><span class="punctuation">.</span><span class="identifier">uniform</span><span class="grouping">(</span><span class="int-literal">0</span><span class="punctuation">,</span> <span class="float-literal">10.0</span><span class="punctuation">,</span> <span class="identifier">size</span><span class="arithmetic-assignment">=</span><span class="int-literal">1000</span><span class="grouping">)</span><span class="grouping">)</span><span class="punctuation">.</span><span class="identifier">T</span>
<span class="identifier">expected_y</span> <span class="arithmetic-assignment">=</span> <span class="identifier">f</span><span class="grouping">(</span><span class="identifier">X</span><span class="grouping">)</span><span class="punctuation">.</span><span class="identifier">ravel</span><span class="grouping">(</span><span class="grouping">)</span>

<span class="comment"># %%</span>
<span class="comment"># To make the problem interesting, we generate observations of the target y as</span>
<span class="comment"># the sum of a deterministic term computed by the function f and a random noise</span>
<span class="comment"># term that follows a centered `log-normal</span>
<span class="comment"># &lt;https://en.wikipedia.org/wiki/Log-normal_distribution&gt;`_. To make this even</span>
<span class="comment"># more interesting we consider the case where the amplitude of the noise</span>
<span class="comment"># depends on the input variable x (heteroscedastic noise).</span>
<span class="comment">#</span>
<span class="comment"># The lognormal distribution is non-symmetric and long tailed: observing large</span>
<span class="comment"># outliers is likely but it is impossible to observe small outliers.</span>
<span class="identifier">sigma</span> <span class="arithmetic-assignment">=</span> <span class="float-literal">0.5</span> <span class="arithmetic-operator">+</span> <span class="identifier">X</span><span class="punctuation">.</span><span class="identifier">ravel</span><span class="grouping">(</span><span class="grouping">)</span> <span class="arithmetic-operator">/</span> <span class="int-literal">10</span>
<span class="identifier">noise</span> <span class="arithmetic-assignment">=</span> <span class="identifier">rng</span><span class="punctuation">.</span><span class="identifier">lognormal</span><span class="grouping">(</span><span class="identifier">sigma</span><span class="arithmetic-assignment">=</span><span class="identifier">sigma</span><span class="grouping">)</span> <span class="arithmetic-operator">-</span> <span class="identifier">np</span><span class="punctuation">.</span><span class="identifier">exp</span><span class="grouping">(</span><span class="identifier">sigma</span> <span class="arithmetic-operator">**</span> <span class="int-literal">2</span> <span class="arithmetic-operator">/</span> <span class="int-literal">2</span><span class="grouping">)</span>
<span class="identifier">y</span> <span class="arithmetic-assignment">=</span> <span class="identifier">expected_y</span> <span class="arithmetic-operator">+</span> <span class="identifier">noise</span>

<span class="comment"># %%</span>
<span class="comment"># Split into train, test datasets:</span>
<span class="identifier">X_train</span><span class="punctuation">,</span> <span class="identifier">X_test</span><span class="punctuation">,</span> <span class="identifier">y_train</span><span class="punctuation">,</span> <span class="identifier">y_test</span> <span class="arithmetic-assignment">=</span> <span class="identifier">train_test_split</span><span class="grouping">(</span><span class="identifier">X</span><span class="punctuation">,</span> <span class="identifier">y</span><span class="punctuation">,</span> <span class="identifier">random_state</span><span class="arithmetic-assignment">=</span><span class="int-literal">0</span><span class="grouping">)</span>

<span class="comment"># %%</span>
<span class="comment"># Fitting non-linear quantile and least squares regressors</span>
<span class="comment"># --------------------------------------------------------</span>
<span class="comment">#</span>
<span class="comment"># Fit gradient boosting models trained with the quantile loss and</span>
<span class="comment"># alpha=0.05, 0.5, 0.95.</span>
<span class="comment">#</span>
<span class="comment"># The models obtained for alpha=0.05 and alpha=0.95 produce a 90% confidence</span>
<span class="comment"># interval (95% - 5% = 90%).</span>
<span class="comment">#</span>
<span class="comment"># The model trained with alpha=0.5 produces a regression of the median: on</span>
<span class="comment"># average, there should be the same number of target observations above and</span>
<span class="comment"># below the predicted values.</span>
<span class="keyword">from</span> <span class="identifier">sklearn</span><span class="punctuation">.</span><span class="identifier">ensemble</span> <span class="keyword">import</span> <span class="identifier">GradientBoostingRegressor</span>
<span class="keyword">from</span> <span class="identifier">sklearn</span><span class="punctuation">.</span><span class="identifier">metrics</span> <span class="keyword">import</span> <span class="identifier">mean_pinball_loss</span><span class="punctuation">,</span> <span class="identifier">mean_squared_error</span>


<span class="identifier">all_models</span> <span class="arithmetic-assignment">=</span> <span class="grouping">{</span><span class="grouping">}</span>
<span class="identifier">common_params</span> <span class="arithmetic-assignment">=</span> <span class="identifier">dict</span><span class="grouping">(</span>
    <span class="identifier">learning_rate</span><span class="arithmetic-assignment">=</span><span class="float-literal">0.05</span><span class="punctuation">,</span>
    <span class="identifier">n_estimators</span><span class="arithmetic-assignment">=</span><span class="int-literal">250</span><span class="punctuation">,</span>
    <span class="identifier">max_depth</span><span class="arithmetic-assignment">=</span><span class="int-literal">2</span><span class="punctuation">,</span>
    <span class="identifier">min_samples_leaf</span><span class="arithmetic-assignment">=</span><span class="int-literal">9</span><span class="punctuation">,</span>
    <span class="identifier">min_samples_split</span><span class="arithmetic-assignment">=</span><span class="int-literal">9</span><span class="punctuation">,</span>
<span class="grouping">)</span>
<span class="keyword">for</span> <span class="identifier">alpha</span> <span class="relational-operator">in</span> <span class="grouping">[</span><span class="float-literal">0.05</span><span class="punctuation">,</span> <span class="float-literal">0.5</span><span class="punctuation">,</span> <span class="float-literal">0.95</span><span class="grouping">]</span><span class="punctuation">:</span>
    <span class="identifier">gbr</span> <span class="arithmetic-assignment">=</span> <span class="identifier">GradientBoostingRegressor</span><span class="grouping">(</span><span class="identifier">loss</span><span class="arithmetic-assignment">=</span><span class="string-literal">'quantile'</span><span class="punctuation">,</span> <span class="identifier">alpha</span><span class="arithmetic-assignment">=</span><span class="identifier">alpha</span><span class="punctuation">,</span>
                                    <span class="arithmetic-operator">**</span><span class="identifier">common_params</span><span class="grouping">)</span>
    <span class="identifier">all_models</span><span class="grouping">[</span><span class="string-literal">"q %1.2f"</span> <span class="arithmetic-operator">%</span> <span class="identifier">alpha</span><span class="grouping">]</span> <span class="arithmetic-assignment">=</span> <span class="identifier">gbr</span><span class="punctuation">.</span><span class="identifier">fit</span><span class="grouping">(</span><span class="identifier">X_train</span><span class="punctuation">,</span> <span class="identifier">y_train</span><span class="grouping">)</span>

<span class="comment"># %%</span>
<span class="comment"># For the sake of comparison, we also fit a baseline model trained with the</span>
<span class="comment"># usual (mean) squared error (MSE).</span>
<span class="identifier">gbr_ls</span> <span class="arithmetic-assignment">=</span> <span class="identifier">GradientBoostingRegressor</span><span class="grouping">(</span><span class="identifier">loss</span><span class="arithmetic-assignment">=</span><span class="string-literal">'squared_error'</span><span class="punctuation">,</span> <span class="arithmetic-operator">**</span><span class="identifier">common_params</span><span class="grouping">)</span>
<span class="identifier">all_models</span><span class="grouping">[</span><span class="string-literal">"mse"</span><span class="grouping">]</span> <span class="arithmetic-assignment">=</span> <span class="identifier">gbr_ls</span><span class="punctuation">.</span><span class="identifier">fit</span><span class="grouping">(</span><span class="identifier">X_train</span><span class="punctuation">,</span> <span class="identifier">y_train</span><span class="grouping">)</span>

<span class="comment"># %%</span>
<span class="comment"># Create an evenly spaced evaluation set of input values spanning the [0, 10]</span>
<span class="comment"># range.</span>
<span class="identifier">xx</span> <span class="arithmetic-assignment">=</span> <span class="identifier">np</span><span class="punctuation">.</span><span class="identifier">atleast_2d</span><span class="grouping">(</span><span class="identifier">np</span><span class="punctuation">.</span><span class="identifier">linspace</span><span class="grouping">(</span><span class="int-literal">0</span><span class="punctuation">,</span> <span class="int-literal">10</span><span class="punctuation">,</span> <span class="int-literal">1000</span><span class="grouping">)</span><span class="grouping">)</span><span class="punctuation">.</span><span class="identifier">T</span>

<span class="comment"># %%</span>
<span class="comment"># Plot the true conditional mean function f, the predictions of the conditional</span>
<span class="comment"># mean (loss equals squared error), the conditional median and the conditional</span>
<span class="comment"># 90% interval (from 5th to 95th conditional percentiles).</span>
<span class="keyword">import</span> <span class="identifier">matplotlib</span><span class="punctuation">.</span><span class="identifier">pyplot</span> <span class="keyword">as</span> <span class="identifier">plt</span>


<span class="identifier">y_pred</span> <span class="arithmetic-assignment">=</span> <span class="identifier">all_models</span><span class="grouping">[</span><span class="string-literal">'mse'</span><span class="grouping">]</span><span class="punctuation">.</span><span class="identifier">predict</span><span class="grouping">(</span><span class="identifier">xx</span><span class="grouping">)</span>
<span class="identifier">y_lower</span> <span class="arithmetic-assignment">=</span> <span class="identifier">all_models</span><span class="grouping">[</span><span class="string-literal">'q 0.05'</span><span class="grouping">]</span><span class="punctuation">.</span><span class="identifier">predict</span><span class="grouping">(</span><span class="identifier">xx</span><span class="grouping">)</span>
<span class="identifier">y_upper</span> <span class="arithmetic-assignment">=</span> <span class="identifier">all_models</span><span class="grouping">[</span><span class="string-literal">'q 0.95'</span><span class="grouping">]</span><span class="punctuation">.</span><span class="identifier">predict</span><span class="grouping">(</span><span class="identifier">xx</span><span class="grouping">)</span>
<span class="identifier">y_med</span> <span class="arithmetic-assignment">=</span> <span class="identifier">all_models</span><span class="grouping">[</span><span class="string-literal">'q 0.50'</span><span class="grouping">]</span><span class="punctuation">.</span><span class="identifier">predict</span><span class="grouping">(</span><span class="identifier">xx</span><span class="grouping">)</span>

<span class="identifier">fig</span> <span class="arithmetic-assignment">=</span> <span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">figure</span><span class="grouping">(</span><span class="identifier">figsize</span><span class="arithmetic-assignment">=</span><span class="grouping">(</span><span class="int-literal">10</span><span class="punctuation">,</span> <span class="int-literal">10</span><span class="grouping">)</span><span class="grouping">)</span>
<span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">plot</span><span class="grouping">(</span><span class="identifier">xx</span><span class="punctuation">,</span> <span class="identifier">f</span><span class="grouping">(</span><span class="identifier">xx</span><span class="grouping">)</span><span class="punctuation">,</span> <span class="string-literal">'g:', linewidth=3, label=r'$f(x) = x\,\sin(x)$'</span><span class="grouping">)</span>
<span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">plot</span><span class="grouping">(</span><span class="identifier">X_test</span><span class="punctuation">,</span> <span class="identifier">y_test</span><span class="punctuation">,</span> <span class="string-literal">'b.', markersize=10, label='Test observations'</span><span class="grouping">)</span>
<span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">plot</span><span class="grouping">(</span><span class="identifier">xx</span><span class="punctuation">,</span> <span class="identifier">y_med</span><span class="punctuation">,</span> <span class="string-literal">'r-', label='Predicted median'</span><span class="punctuation">,</span> <span class="identifier">color</span><span class="arithmetic-assignment">=</span><span class="string-literal">"orange"</span><span class="grouping">)</span>
<span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">plot</span><span class="grouping">(</span><span class="identifier">xx</span><span class="punctuation">,</span> <span class="identifier">y_pred</span><span class="punctuation">,</span> <span class="string-literal">'r-', label='Predicted mean'</span><span class="grouping">)</span>
<span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">plot</span><span class="grouping">(</span><span class="identifier">xx</span><span class="punctuation">,</span> <span class="identifier">y_upper</span><span class="punctuation">,</span> <span class="string-literal">'k-'</span><span class="grouping">)</span>
<span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">plot</span><span class="grouping">(</span><span class="identifier">xx</span><span class="punctuation">,</span> <span class="identifier">y_lower</span><span class="punctuation">,</span> <span class="string-literal">'k-'</span><span class="grouping">)</span>
<span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">fill_between</span><span class="grouping">(</span><span class="identifier">xx</span><span class="punctuation">.</span><span class="identifier">ravel</span><span class="grouping">(</span><span class="grouping">)</span><span class="punctuation">,</span> <span class="identifier">y_lower</span><span class="punctuation">,</span> <span class="identifier">y_upper</span><span class="punctuation">,</span> <span class="identifier">alpha</span><span class="arithmetic-assignment">=</span><span class="float-literal">0.4</span><span class="punctuation">,</span>
                 <span class="identifier">label</span><span class="arithmetic-assignment">=</span><span class="string-literal">'Predicted 90% interval'</span><span class="grouping">)</span>
<span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">xlabel</span><span class="grouping">(</span><span class="string-literal">'$x$'</span><span class="grouping">)</span>
<span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">ylabel</span><span class="grouping">(</span><span class="string-literal">'$f(x)$'</span><span class="grouping">)</span>
<span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">ylim</span><span class="grouping">(</span><span class="arithmetic-operator">-</span><span class="int-literal">10</span><span class="punctuation">,</span> <span class="int-literal">25</span><span class="grouping">)</span>
<span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">legend</span><span class="grouping">(</span><span class="identifier">loc</span><span class="arithmetic-assignment">=</span><span class="string-literal">'upper left'</span><span class="grouping">)</span>
<span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">show</span><span class="grouping">(</span><span class="grouping">)</span>

<span class="comment"># %%</span>
<span class="comment"># Comparing the predicted median with the predicted mean, we note that the</span>
<span class="comment"># median is on average below the mean as the noise is skewed towards high</span>
<span class="comment"># values (large outliers). The median estimate also seems to be smoother</span>
<span class="comment"># because of its natural robustness to outliers.</span>
<span class="comment">#</span>
<span class="comment"># Also observe that the inductive bias of gradient boosting trees is</span>
<span class="comment"># unfortunately preventing our 0.05 quantile to fully capture the sinoisoidal</span>
<span class="comment"># shape of the signal, in particular around x=8. Tuning hyper-parameters can</span>
<span class="comment"># reduce this effect as shown in the last part of this notebook.</span>
<span class="comment">#</span>
<span class="comment"># Analysis of the error metrics</span>
<span class="comment"># -----------------------------</span>
<span class="comment">#</span>
<span class="comment"># Measure the models with :func:`mean_squared_error` and</span>
<span class="comment"># :func:`mean_pinball_loss` metrics on the training dataset.</span>
<span class="keyword">import</span> <span class="identifier">pandas</span> <span class="keyword">as</span> <span class="identifier">pd</span>


<span class="keyword">def</span> <span class="identifier">highlight_min</span><span class="grouping">(</span><span class="identifier">x</span><span class="grouping">)</span><span class="punctuation">:</span>
    <span class="identifier">x_min</span> <span class="arithmetic-assignment">=</span> <span class="identifier">x</span><span class="punctuation">.</span><span class="identifier">min</span><span class="grouping">(</span><span class="grouping">)</span>
    <span class="keyword">return</span> <span class="grouping">[</span><span class="string-literal">'font-weight: bold' if v == x_min else ''</span>
            <span class="keyword">for</span> <span class="identifier">v</span> <span class="relational-operator">in</span> <span class="identifier">x</span><span class="grouping">]</span>


<span class="identifier">results</span> <span class="arithmetic-assignment">=</span> <span class="grouping">[</span><span class="grouping">]</span>
<span class="keyword">for</span> <span class="identifier">name</span><span class="punctuation">,</span> <span class="identifier">gbr</span> <span class="relational-operator">in</span> <span class="identifier">sorted</span><span class="grouping">(</span><span class="identifier">all_models</span><span class="punctuation">.</span><span class="identifier">items</span><span class="grouping">(</span><span class="grouping">)</span><span class="grouping">)</span><span class="punctuation">:</span>
    <span class="identifier">metrics</span> <span class="arithmetic-assignment">=</span> <span class="grouping">{</span><span class="string-literal">'model'</span><span class="punctuation">:</span> <span class="identifier">name</span><span class="grouping">}</span>
    <span class="identifier">y_pred</span> <span class="arithmetic-assignment">=</span> <span class="identifier">gbr</span><span class="punctuation">.</span><span class="identifier">predict</span><span class="grouping">(</span><span class="identifier">X_train</span><span class="grouping">)</span>
    <span class="keyword">for</span> <span class="identifier">alpha</span> <span class="relational-operator">in</span> <span class="grouping">[</span><span class="float-literal">0.05</span><span class="punctuation">,</span> <span class="float-literal">0.5</span><span class="punctuation">,</span> <span class="float-literal">0.95</span><span class="grouping">]</span><span class="punctuation">:</span>
        <span class="identifier">metrics</span><span class="grouping">[</span><span class="string-literal">"pbl=%1.2f"</span> <span class="arithmetic-operator">%</span> <span class="identifier">alpha</span><span class="grouping">]</span> <span class="arithmetic-assignment">=</span> <span class="identifier">mean_pinball_loss</span><span class="grouping">(</span>
            <span class="identifier">y_train</span><span class="punctuation">,</span> <span class="identifier">y_pred</span><span class="punctuation">,</span> <span class="identifier">alpha</span><span class="arithmetic-assignment">=</span><span class="identifier">alpha</span><span class="grouping">)</span>
    <span class="identifier">metrics</span><span class="grouping">[</span><span class="string-literal">'MSE'</span><span class="grouping">]</span> <span class="arithmetic-assignment">=</span> <span class="identifier">mean_squared_error</span><span class="grouping">(</span><span class="identifier">y_train</span><span class="punctuation">,</span> <span class="identifier">y_pred</span><span class="grouping">)</span>
    <span class="identifier">results</span><span class="punctuation">.</span><span class="identifier">append</span><span class="grouping">(</span><span class="identifier">metrics</span><span class="grouping">)</span>

<span class="identifier">pd</span><span class="punctuation">.</span><span class="identifier">DataFrame</span><span class="grouping">(</span><span class="identifier">results</span><span class="grouping">)</span><span class="punctuation">.</span><span class="identifier">set_index</span><span class="grouping">(</span><span class="string-literal">'model'</span><span class="grouping">)</span><span class="punctuation">.</span><span class="identifier">style</span><span class="punctuation">.</span><span class="identifier">apply</span><span class="grouping">(</span><span class="identifier">highlight_min</span><span class="grouping">)</span>

<span class="comment"># %%</span>
<span class="comment"># One column shows all models evaluated by the same metric. The minimum number</span>
<span class="comment"># on a column should be obtained when the model is trained and measured with</span>
<span class="comment"># the same metric. This should be always the case on the training set if the</span>
<span class="comment"># training converged.</span>
<span class="comment">#</span>
<span class="comment"># Note that because the target distribution is asymmetric, the expected</span>
<span class="comment"># conditional mean and conditional median are signficiantly different and</span>
<span class="comment"># therefore one could not use the squared error model get a good estimation of</span>
<span class="comment"># the conditional median nor the converse.</span>
<span class="comment">#</span>
<span class="comment"># If the target distribution were symmetric and had no outliers (e.g. with a</span>
<span class="comment"># Gaussian noise), then median estimator and the least squares estimator would</span>
<span class="comment"># have yielded similar predictions.</span>
<span class="comment">#</span>
<span class="comment"># We then do the same on the test set.</span>
<span class="identifier">results</span> <span class="arithmetic-assignment">=</span> <span class="grouping">[</span><span class="grouping">]</span>
<span class="keyword">for</span> <span class="identifier">name</span><span class="punctuation">,</span> <span class="identifier">gbr</span> <span class="relational-operator">in</span> <span class="identifier">sorted</span><span class="grouping">(</span><span class="identifier">all_models</span><span class="punctuation">.</span><span class="identifier">items</span><span class="grouping">(</span><span class="grouping">)</span><span class="grouping">)</span><span class="punctuation">:</span>
    <span class="identifier">metrics</span> <span class="arithmetic-assignment">=</span> <span class="grouping">{</span><span class="string-literal">'model'</span><span class="punctuation">:</span> <span class="identifier">name</span><span class="grouping">}</span>
    <span class="identifier">y_pred</span> <span class="arithmetic-assignment">=</span> <span class="identifier">gbr</span><span class="punctuation">.</span><span class="identifier">predict</span><span class="grouping">(</span><span class="identifier">X_test</span><span class="grouping">)</span>
    <span class="keyword">for</span> <span class="identifier">alpha</span> <span class="relational-operator">in</span> <span class="grouping">[</span><span class="float-literal">0.05</span><span class="punctuation">,</span> <span class="float-literal">0.5</span><span class="punctuation">,</span> <span class="float-literal">0.95</span><span class="grouping">]</span><span class="punctuation">:</span>
        <span class="identifier">metrics</span><span class="grouping">[</span><span class="string-literal">"pbl=%1.2f"</span> <span class="arithmetic-operator">%</span> <span class="identifier">alpha</span><span class="grouping">]</span> <span class="arithmetic-assignment">=</span> <span class="identifier">mean_pinball_loss</span><span class="grouping">(</span>
            <span class="identifier">y_test</span><span class="punctuation">,</span> <span class="identifier">y_pred</span><span class="punctuation">,</span> <span class="identifier">alpha</span><span class="arithmetic-assignment">=</span><span class="identifier">alpha</span><span class="grouping">)</span>
    <span class="identifier">metrics</span><span class="grouping">[</span><span class="string-literal">'MSE'</span><span class="grouping">]</span> <span class="arithmetic-assignment">=</span> <span class="identifier">mean_squared_error</span><span class="grouping">(</span><span class="identifier">y_test</span><span class="punctuation">,</span> <span class="identifier">y_pred</span><span class="grouping">)</span>
    <span class="identifier">results</span><span class="punctuation">.</span><span class="identifier">append</span><span class="grouping">(</span><span class="identifier">metrics</span><span class="grouping">)</span>

<span class="identifier">pd</span><span class="punctuation">.</span><span class="identifier">DataFrame</span><span class="grouping">(</span><span class="identifier">results</span><span class="grouping">)</span><span class="punctuation">.</span><span class="identifier">set_index</span><span class="grouping">(</span><span class="string-literal">'model'</span><span class="grouping">)</span><span class="punctuation">.</span><span class="identifier">style</span><span class="punctuation">.</span><span class="identifier">apply</span><span class="grouping">(</span><span class="identifier">highlight_min</span><span class="grouping">)</span>


<span class="comment"># %%</span>
<span class="comment"># Errors are higher meaning the models slightly overfitted the data. It still</span>
<span class="comment"># shows that the best test metric is obtained when the model is trained by</span>
<span class="comment"># minimizing this same metric.</span>
<span class="comment">#</span>
<span class="comment"># Note that the conditional median estimator is competitive with the squared</span>
<span class="comment"># error estimator in terms of MSE on the test set: this can be explained by</span>
<span class="comment"># the fact the squared error estimator is very sensitive to large outliers</span>
<span class="comment"># which can cause significant overfitting. This can be seen on the right hand</span>
<span class="comment"># side of the previous plot. The conditional median estimator is biased</span>
<span class="comment"># (underestimation for this asymetric noise) but is also naturally robust to</span>
<span class="comment"># outliers and overfits less.</span>
<span class="comment">#</span>
<span class="comment"># Calibration of the confidence interval</span>
<span class="comment"># --------------------------------------</span>
<span class="comment">#</span>
<span class="comment"># We can also evaluate the ability of the two extreme quantile estimators at</span>
<span class="comment"># producing a well-calibrated conditational 90%-confidence interval.</span>
<span class="comment">#</span>
<span class="comment"># To do this we can compute the fraction of observations that fall between the</span>
<span class="comment"># predictions:</span>
<span class="keyword">def</span> <span class="identifier">coverage_fraction</span><span class="grouping">(</span><span class="identifier">y</span><span class="punctuation">,</span> <span class="identifier">y_low</span><span class="punctuation">,</span> <span class="identifier">y_high</span><span class="grouping">)</span><span class="punctuation">:</span>
    <span class="keyword">return</span> <span class="identifier">np</span><span class="punctuation">.</span><span class="identifier">mean</span><span class="grouping">(</span><span class="identifier">np</span><span class="punctuation">.</span><span class="identifier">logical_and</span><span class="grouping">(</span><span class="identifier">y</span> <span class="relational-operator">&gt;=</span> <span class="identifier">y_low</span><span class="punctuation">,</span> <span class="identifier">y</span> <span class="relational-operator">&lt;=</span> <span class="identifier">y_high</span><span class="grouping">)</span><span class="grouping">)</span>


<span class="identifier">coverage_fraction</span><span class="grouping">(</span><span class="identifier">y_train</span><span class="punctuation">,</span>
                  <span class="identifier">all_models</span><span class="grouping">[</span><span class="string-literal">'q 0.05'</span><span class="grouping">]</span><span class="punctuation">.</span><span class="identifier">predict</span><span class="grouping">(</span><span class="identifier">X_train</span><span class="grouping">)</span><span class="punctuation">,</span>
                  <span class="identifier">all_models</span><span class="grouping">[</span><span class="string-literal">'q 0.95'</span><span class="grouping">]</span><span class="punctuation">.</span><span class="identifier">predict</span><span class="grouping">(</span><span class="identifier">X_train</span><span class="grouping">)</span><span class="grouping">)</span>

<span class="comment"># %%</span>
<span class="comment"># On the training set the calibration is very close to the expected coverage</span>
<span class="comment"># value for a 90% confidence interval.</span>
<span class="identifier">coverage_fraction</span><span class="grouping">(</span><span class="identifier">y_test</span><span class="punctuation">,</span>
                  <span class="identifier">all_models</span><span class="grouping">[</span><span class="string-literal">'q 0.05'</span><span class="grouping">]</span><span class="punctuation">.</span><span class="identifier">predict</span><span class="grouping">(</span><span class="identifier">X_test</span><span class="grouping">)</span><span class="punctuation">,</span>
                  <span class="identifier">all_models</span><span class="grouping">[</span><span class="string-literal">'q 0.95'</span><span class="grouping">]</span><span class="punctuation">.</span><span class="identifier">predict</span><span class="grouping">(</span><span class="identifier">X_test</span><span class="grouping">)</span><span class="grouping">)</span>


<span class="comment"># %%</span>
<span class="comment"># On the test set, the estimated confidence interval is slightly too narrow.</span>
<span class="comment"># Note, however, that we would need to wrap those metrics in a cross-validation</span>
<span class="comment"># loop to assess their variability under data resampling.</span>
<span class="comment">#</span>
<span class="comment"># Tuning the hyper-parameters of the quantile regressors</span>
<span class="comment"># ------------------------------------------------------</span>
<span class="comment">#</span>
<span class="comment"># In the plot above, we observed that the 5th percentile regressor seems to</span>
<span class="comment"># underfit and could not adapt to sinusoidal shape of the signal.</span>
<span class="comment">#</span>
<span class="comment"># The hyper-parameters of the model were approximately hand-tuned for the</span>
<span class="comment"># median regressor and there is no reason than the same hyper-parameters are</span>
<span class="comment"># suitable for the 5th percentile regressor.</span>
<span class="comment">#</span>
<span class="comment"># To confirm this hypothesis, we tune the hyper-parameters of a new regressor</span>
<span class="comment"># of the 5th percentile by selecting the best model parameters by</span>
<span class="comment"># cross-validation on the pinball loss with alpha=0.05:</span>

<span class="comment"># %%</span>
<span class="keyword">from</span> <span class="identifier">sklearn</span><span class="punctuation">.</span><span class="identifier">model_selection</span> <span class="keyword">import</span> <span class="identifier">RandomizedSearchCV</span>
<span class="keyword">from</span> <span class="identifier">sklearn</span><span class="punctuation">.</span><span class="identifier">metrics</span> <span class="keyword">import</span> <span class="identifier">make_scorer</span>
<span class="keyword">from</span> <span class="identifier">pprint</span> <span class="keyword">import</span> <span class="identifier">pprint</span>


<span class="identifier">param_grid</span> <span class="arithmetic-assignment">=</span> <span class="identifier">dict</span><span class="grouping">(</span>
    <span class="identifier">learning_rate</span><span class="arithmetic-assignment">=</span><span class="grouping">[</span><span class="float-literal">0.01</span><span class="punctuation">,</span> <span class="float-literal">0.05</span><span class="punctuation">,</span> <span class="float-literal">0.1</span><span class="grouping">]</span><span class="punctuation">,</span>
    <span class="identifier">n_estimators</span><span class="arithmetic-assignment">=</span><span class="grouping">[</span><span class="int-literal">100</span><span class="punctuation">,</span> <span class="int-literal">150</span><span class="punctuation">,</span> <span class="int-literal">200</span><span class="punctuation">,</span> <span class="int-literal">250</span><span class="punctuation">,</span> <span class="int-literal">300</span><span class="grouping">]</span><span class="punctuation">,</span>
    <span class="identifier">max_depth</span><span class="arithmetic-assignment">=</span><span class="grouping">[</span><span class="int-literal">2</span><span class="punctuation">,</span> <span class="int-literal">5</span><span class="punctuation">,</span> <span class="int-literal">10</span><span class="punctuation">,</span> <span class="int-literal">15</span><span class="punctuation">,</span> <span class="int-literal">20</span><span class="grouping">]</span><span class="punctuation">,</span>
    <span class="identifier">min_samples_leaf</span><span class="arithmetic-assignment">=</span><span class="grouping">[</span><span class="int-literal">1</span><span class="punctuation">,</span> <span class="int-literal">5</span><span class="punctuation">,</span> <span class="int-literal">10</span><span class="punctuation">,</span> <span class="int-literal">20</span><span class="punctuation">,</span> <span class="int-literal">30</span><span class="punctuation">,</span> <span class="int-literal">50</span><span class="grouping">]</span><span class="punctuation">,</span>
    <span class="identifier">min_samples_split</span><span class="arithmetic-assignment">=</span><span class="grouping">[</span><span class="int-literal">2</span><span class="punctuation">,</span> <span class="int-literal">5</span><span class="punctuation">,</span> <span class="int-literal">10</span><span class="punctuation">,</span> <span class="int-literal">20</span><span class="punctuation">,</span> <span class="int-literal">30</span><span class="punctuation">,</span> <span class="int-literal">50</span><span class="grouping">]</span><span class="punctuation">,</span>
<span class="grouping">)</span>
<span class="identifier">alpha</span> <span class="arithmetic-assignment">=</span> <span class="float-literal">0.05</span>
<span class="identifier">neg_mean_pinball_loss_05p_scorer</span> <span class="arithmetic-assignment">=</span> <span class="identifier">make_scorer</span><span class="grouping">(</span>
    <span class="identifier">mean_pinball_loss</span><span class="punctuation">,</span>
    <span class="identifier">alpha</span><span class="arithmetic-assignment">=</span><span class="identifier">alpha</span><span class="punctuation">,</span>
    <span class="identifier">greater_is_better</span><span class="arithmetic-assignment">=</span><span class="bool-literal">False</span><span class="punctuation">,</span>  <span class="comment"># maximize the negative loss</span>
<span class="grouping">)</span>
<span class="identifier">gbr</span> <span class="arithmetic-assignment">=</span> <span class="identifier">GradientBoostingRegressor</span><span class="grouping">(</span><span class="identifier">loss</span><span class="arithmetic-assignment">=</span><span class="string-literal">"quantile"</span><span class="punctuation">,</span> <span class="identifier">alpha</span><span class="arithmetic-assignment">=</span><span class="identifier">alpha</span><span class="punctuation">,</span> <span class="identifier">random_state</span><span class="arithmetic-assignment">=</span><span class="int-literal">0</span><span class="grouping">)</span>
<span class="identifier">search_05p</span> <span class="arithmetic-assignment">=</span> <span class="identifier">RandomizedSearchCV</span><span class="grouping">(</span>
    <span class="identifier">gbr</span><span class="punctuation">,</span>
    <span class="identifier">param_grid</span><span class="punctuation">,</span>
    <span class="identifier">n_iter</span><span class="arithmetic-assignment">=</span><span class="int-literal">10</span><span class="punctuation">,</span>  <span class="comment"># increase this if computational budget allows</span>
    <span class="identifier">scoring</span><span class="arithmetic-assignment">=</span><span class="identifier">neg_mean_pinball_loss_05p_scorer</span><span class="punctuation">,</span>
    <span class="identifier">n_jobs</span><span class="arithmetic-assignment">=</span><span class="int-literal">2</span><span class="punctuation">,</span>
    <span class="identifier">random_state</span><span class="arithmetic-assignment">=</span><span class="int-literal">0</span><span class="punctuation">,</span>
<span class="grouping">)</span><span class="punctuation">.</span><span class="identifier">fit</span><span class="grouping">(</span><span class="identifier">X_train</span><span class="punctuation">,</span> <span class="identifier">y_train</span><span class="grouping">)</span>
<span class="identifier">pprint</span><span class="grouping">(</span><span class="identifier">search_05p</span><span class="punctuation">.</span><span class="identifier">best_params_</span><span class="grouping">)</span>

<span class="comment"># %%</span>
<span class="comment"># We observe that the search procedure identifies that deeper trees are needed</span>
<span class="comment"># to get a good fit for the 5th percentile regressor. Deeper trees are more</span>
<span class="comment"># expressive and less likely to underfit.</span>
<span class="comment">#</span>
<span class="comment"># Let's now tune the hyper-parameters for the 95th percentile regressor. We</span>
<span class="comment"># need to redefine the `scoring` metric used to select the best model, along</span>
<span class="comment"># with adjusting the alpha parameter of the inner gradient boosting estimator</span>
<span class="comment"># itself:</span>
<span class="keyword">from</span> <span class="identifier">sklearn</span><span class="punctuation">.</span><span class="identifier">base</span> <span class="keyword">import</span> <span class="identifier">clone</span>

<span class="identifier">alpha</span> <span class="arithmetic-assignment">=</span> <span class="float-literal">0.95</span>
<span class="identifier">neg_mean_pinball_loss_95p_scorer</span> <span class="arithmetic-assignment">=</span> <span class="identifier">make_scorer</span><span class="grouping">(</span>
    <span class="identifier">mean_pinball_loss</span><span class="punctuation">,</span>
    <span class="identifier">alpha</span><span class="arithmetic-assignment">=</span><span class="identifier">alpha</span><span class="punctuation">,</span>
    <span class="identifier">greater_is_better</span><span class="arithmetic-assignment">=</span><span class="bool-literal">False</span><span class="punctuation">,</span>  <span class="comment"># maximize the negative loss</span>
<span class="grouping">)</span>
<span class="identifier">search_95p</span> <span class="arithmetic-assignment">=</span> <span class="identifier">clone</span><span class="grouping">(</span><span class="identifier">search_05p</span><span class="grouping">)</span><span class="punctuation">.</span><span class="identifier">set_params</span><span class="grouping">(</span>
    <span class="identifier">estimator__alpha</span><span class="arithmetic-assignment">=</span><span class="identifier">alpha</span><span class="punctuation">,</span>
    <span class="identifier">scoring</span><span class="arithmetic-assignment">=</span><span class="identifier">neg_mean_pinball_loss_95p_scorer</span><span class="punctuation">,</span>
<span class="grouping">)</span>
<span class="identifier">search_95p</span><span class="punctuation">.</span><span class="identifier">fit</span><span class="grouping">(</span><span class="identifier">X_train</span><span class="punctuation">,</span> <span class="identifier">y_train</span><span class="grouping">)</span>
<span class="identifier">pprint</span><span class="grouping">(</span><span class="identifier">search_95p</span><span class="punctuation">.</span><span class="identifier">best_params_</span><span class="grouping">)</span>

<span class="comment"># %%</span>
<span class="comment"># This time, shallower trees are selected and lead to a more constant piecewise</span>
<span class="comment"># and therefore more robust estimation of the 95th percentile. This is</span>
<span class="comment"># beneficial as it avoids overfitting the large outliers of the log-normal</span>
<span class="comment"># additive noise.</span>
<span class="comment">#</span>
<span class="comment"># We can confirm this intuition by displaying the predicted 90% confidence</span>
<span class="comment"># interval comprised by the predictions of those two tuned quantile regressors:</span>
<span class="comment"># the prediction of the upper 95th percentile has a much coarser shape than the</span>
<span class="comment"># prediction of the lower 5th percentile:</span>
<span class="identifier">y_lower</span> <span class="arithmetic-assignment">=</span> <span class="identifier">search_05p</span><span class="punctuation">.</span><span class="identifier">predict</span><span class="grouping">(</span><span class="identifier">xx</span><span class="grouping">)</span>
<span class="identifier">y_upper</span> <span class="arithmetic-assignment">=</span> <span class="identifier">search_95p</span><span class="punctuation">.</span><span class="identifier">predict</span><span class="grouping">(</span><span class="identifier">xx</span><span class="grouping">)</span>

<span class="identifier">fig</span> <span class="arithmetic-assignment">=</span> <span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">figure</span><span class="grouping">(</span><span class="identifier">figsize</span><span class="arithmetic-assignment">=</span><span class="grouping">(</span><span class="int-literal">10</span><span class="punctuation">,</span> <span class="int-literal">10</span><span class="grouping">)</span><span class="grouping">)</span>
<span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">plot</span><span class="grouping">(</span><span class="identifier">xx</span><span class="punctuation">,</span> <span class="identifier">f</span><span class="grouping">(</span><span class="identifier">xx</span><span class="grouping">)</span><span class="punctuation">,</span> <span class="string-literal">'g:', linewidth=3, label=r'$f(x) = x\,\sin(x)$'</span><span class="grouping">)</span>
<span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">plot</span><span class="grouping">(</span><span class="identifier">X_test</span><span class="punctuation">,</span> <span class="identifier">y_test</span><span class="punctuation">,</span> <span class="string-literal">'b.', markersize=10, label='Test observations'</span><span class="grouping">)</span>
<span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">plot</span><span class="grouping">(</span><span class="identifier">xx</span><span class="punctuation">,</span> <span class="identifier">y_upper</span><span class="punctuation">,</span> <span class="string-literal">'k-'</span><span class="grouping">)</span>
<span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">plot</span><span class="grouping">(</span><span class="identifier">xx</span><span class="punctuation">,</span> <span class="identifier">y_lower</span><span class="punctuation">,</span> <span class="string-literal">'k-'</span><span class="grouping">)</span>
<span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">fill_between</span><span class="grouping">(</span><span class="identifier">xx</span><span class="punctuation">.</span><span class="identifier">ravel</span><span class="grouping">(</span><span class="grouping">)</span><span class="punctuation">,</span> <span class="identifier">y_lower</span><span class="punctuation">,</span> <span class="identifier">y_upper</span><span class="punctuation">,</span> <span class="identifier">alpha</span><span class="arithmetic-assignment">=</span><span class="float-literal">0.4</span><span class="punctuation">,</span>
                 <span class="identifier">label</span><span class="arithmetic-assignment">=</span><span class="string-literal">'Predicted 90% interval'</span><span class="grouping">)</span>
<span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">xlabel</span><span class="grouping">(</span><span class="string-literal">'$x$'</span><span class="grouping">)</span>
<span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">ylabel</span><span class="grouping">(</span><span class="string-literal">'$f(x)$'</span><span class="grouping">)</span>
<span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">ylim</span><span class="grouping">(</span><span class="arithmetic-operator">-</span><span class="int-literal">10</span><span class="punctuation">,</span> <span class="int-literal">25</span><span class="grouping">)</span>
<span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">legend</span><span class="grouping">(</span><span class="identifier">loc</span><span class="arithmetic-assignment">=</span><span class="string-literal">'upper left'</span><span class="grouping">)</span>
<span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">title</span><span class="grouping">(</span><span class="string-literal">"Prediction with tuned hyper-parameters"</span><span class="grouping">)</span>
<span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">show</span><span class="grouping">(</span><span class="grouping">)</span>

<span class="comment"># %%</span>
<span class="comment"># The plot looks qualitatively better than for the untuned models, especially</span>
<span class="comment"># for the shape of the of lower quantile.</span>
<span class="comment">#</span>
<span class="comment"># We now quantitatively evaluate the joint-calibration of the pair of</span>
<span class="comment"># estimators:</span>
<span class="identifier">coverage_fraction</span><span class="grouping">(</span><span class="identifier">y_train</span><span class="punctuation">,</span>
                  <span class="identifier">search_05p</span><span class="punctuation">.</span><span class="identifier">predict</span><span class="grouping">(</span><span class="identifier">X_train</span><span class="grouping">)</span><span class="punctuation">,</span>
                  <span class="identifier">search_95p</span><span class="punctuation">.</span><span class="identifier">predict</span><span class="grouping">(</span><span class="identifier">X_train</span><span class="grouping">)</span><span class="grouping">)</span>
<span class="comment"># %%</span>
<span class="identifier">coverage_fraction</span><span class="grouping">(</span><span class="identifier">y_test</span><span class="punctuation">,</span>
                  <span class="identifier">search_05p</span><span class="punctuation">.</span><span class="identifier">predict</span><span class="grouping">(</span><span class="identifier">X_test</span><span class="grouping">)</span><span class="punctuation">,</span>
                  <span class="identifier">search_95p</span><span class="punctuation">.</span><span class="identifier">predict</span><span class="grouping">(</span><span class="identifier">X_test</span><span class="grouping">)</span><span class="grouping">)</span>
<span class="comment"># %%</span>
<span class="comment"># The calibration of the tuned pair is sadly not better on the test set: the</span>
<span class="comment"># width of the estimated confidence interval is still too narrow.</span>
<span class="comment">#</span>
<span class="comment"># Again, we would need to wrap this study in a cross-validation loop to</span>
<span class="comment"># better assess the variability of those estimates.</span>

    </pre>
  </body>
</html>
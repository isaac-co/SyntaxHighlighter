<html>
  <head>
    <title>Python Lexical Highliter</title>
    <link rel="stylesheet" href="token_colors.css">
  </head>
  <body>
    <pre><span class="comment">"""
================================================
Categorical Feature Support in Gradient Boosting
================================================

.. currentmodule:: sklearn

In this example, we will compare the training times and prediction
performances of :class:`~ensemble.HistGradientBoostingRegressor` with
different encoding strategies for categorical features. In
particular, we will evaluate:

- dropping the categorical features
- using a :class:`~preprocessing.OneHotEncoder`
- using an :class:`~preprocessing.OrdinalEncoder` and treat categories as
  ordered, equidistant quantities
- using an :class:`~preprocessing.OrdinalEncoder` and rely on the :ref:`native
  category support &lt;categorical_support_gbdt&gt;` of the
  :class:`~ensemble.HistGradientBoostingRegressor` estimator.

We will work with the Ames Lowa Housing dataset which consists of numerical
and categorical features, where the houses' sales prices is the target.
"""</span>
<span class="identifier">print</span><span class="grouping">(</span><span class="identifier">__doc__</span><span class="grouping">)</span>

<span class="comment"># %%</span>
<span class="comment"># Load Ames Housing dataset</span>
<span class="comment"># -------------------------</span>
<span class="comment"># First, we load the ames housing data as a pandas dataframe. The features</span>
<span class="comment"># are either categorical or numerical:</span>
<span class="keyword">from</span> <span class="identifier">sklearn</span><span class="punctuation">.</span><span class="identifier">datasets</span> <span class="keyword">import</span> <span class="identifier">fetch_openml</span>

<span class="identifier">X</span><span class="punctuation">,</span> <span class="identifier">y</span> <span class="arithmetic-assignment">=</span> <span class="identifier">fetch_openml</span><span class="grouping">(</span><span class="identifier">data_id</span><span class="arithmetic-assignment">=</span><span class="int-literal">41211</span><span class="punctuation">,</span> <span class="invalid">a</span><span class="invalid">s</span><span class="invalid">_</span><span class="invalid">f</span><span class="invalid">r</span><span class="invalid">a</span><span class="invalid">m</span><span class="invalid">e</span><span class="arithmetic-assignment">=</span><span class="bool-literal">True</span><span class="punctuation">,</span> <span class="invalid">r</span><span class="invalid">e</span><span class="invalid">t</span><span class="invalid">u</span><span class="invalid">r</span><span class="invalid">n</span><span class="invalid">_</span><span class="invalid">X</span><span class="invalid">_</span><span class="invalid">y</span><span class="arithmetic-assignment">=</span><span class="bool-literal">True</span><span class="grouping">)</span>

<span class="identifier">n_categorical_features</span> <span class="arithmetic-assignment">=</span> <span class="grouping">(</span><span class="identifier">X</span><span class="punctuation">.</span><span class="identifier">dtypes</span> <span class="relational-operator">==</span> <span class="string-literal">'category'</span><span class="grouping">)</span><span class="punctuation">.</span><span class="identifier">sum</span><span class="grouping">(</span><span class="grouping">)</span>
<span class="identifier">n_numerical_features</span> <span class="arithmetic-assignment">=</span> <span class="grouping">(</span><span class="identifier">X</span><span class="punctuation">.</span><span class="identifier">dtypes</span> <span class="relational-operator">==</span> <span class="string-literal">'float'</span><span class="grouping">)</span><span class="punctuation">.</span><span class="identifier">sum</span><span class="grouping">(</span><span class="grouping">)</span>
<span class="identifier">print</span><span class="grouping">(</span><span class="identifier">f</span><span class="string-literal">"Number of samples: {X.shape[0]}"</span><span class="grouping">)</span>
<span class="identifier">print</span><span class="grouping">(</span><span class="identifier">f</span><span class="string-literal">"Number of features: {X.shape[1]}"</span><span class="grouping">)</span>
<span class="identifier">print</span><span class="grouping">(</span><span class="identifier">f</span><span class="string-literal">"Number of categorical features: {n_categorical_features}"</span><span class="grouping">)</span>
<span class="identifier">print</span><span class="grouping">(</span><span class="identifier">f</span><span class="string-literal">"Number of numerical features: {n_numerical_features}"</span><span class="grouping">)</span>

<span class="comment"># %%</span>
<span class="comment"># Gradient boosting estimator with dropped categorical features</span>
<span class="comment"># -------------------------------------------------------------</span>
<span class="comment"># As a baseline, we create an estimator where the categorical features are</span>
<span class="comment"># dropped:</span>

<span class="keyword">from</span> <span class="identifier">sklearn</span><span class="punctuation">.</span><span class="identifier">ensemble</span> <span class="keyword">import</span> <span class="identifier">HistGradientBoostingRegressor</span>
<span class="keyword">from</span> <span class="identifier">sklearn</span><span class="punctuation">.</span><span class="identifier">pipeline</span> <span class="keyword">import</span> <span class="identifier">make_pipeline</span>
<span class="keyword">from</span> <span class="identifier">sklearn</span><span class="punctuation">.</span><span class="identifier">compose</span> <span class="keyword">import</span> <span class="identifier">make_column_transformer</span>
<span class="keyword">from</span> <span class="identifier">sklearn</span><span class="punctuation">.</span><span class="identifier">compose</span> <span class="keyword">import</span> <span class="identifier">make_column_selector</span>

<span class="identifier">dropper</span> <span class="arithmetic-assignment">=</span> <span class="identifier">make_column_transformer</span><span class="grouping">(</span>
    <span class="grouping">(</span><span class="string-literal">'drop', make_column_selector(dtype_include='category'</span><span class="grouping">)</span><span class="grouping">)</span><span class="punctuation">,</span>
    <span class="identifier">remainder</span><span class="arithmetic-assignment">=</span><span class="string-literal">'passthrough'</span><span class="grouping">)</span>
<span class="identifier">hist_dropped</span> <span class="arithmetic-assignment">=</span> <span class="identifier">make_pipeline</span><span class="grouping">(</span><span class="identifier">dropper</span><span class="punctuation">,</span>
                             <span class="identifier">HistGradientBoostingRegressor</span><span class="grouping">(</span><span class="identifier">random_state</span><span class="arithmetic-assignment">=</span><span class="int-literal">42</span><span class="grouping">)</span><span class="grouping">)</span>

<span class="comment"># %%</span>
<span class="comment"># Gradient boosting estimator with one-hot encoding</span>
<span class="comment"># -------------------------------------------------</span>
<span class="comment"># Next, we create a pipeline that will one-hot encode the categorical features</span>
<span class="comment"># and let the rest of the numerical data to passthrough:</span>

<span class="keyword">from</span> <span class="identifier">sklearn</span><span class="punctuation">.</span><span class="identifier">preprocessing</span> <span class="keyword">import</span> <span class="identifier">OneHotEncoder</span>

<span class="identifier">one_hot_encoder</span> <span class="arithmetic-assignment">=</span> <span class="identifier">make_column_transformer</span><span class="grouping">(</span>
    <span class="grouping">(</span><span class="identifier">OneHotEncoder</span><span class="grouping">(</span><span class="identifier">sparse</span><span class="arithmetic-assignment">=</span><span class="bool-literal">False</span><span class="punctuation">,</span> <span class="identifier">handle_unknown</span><span class="arithmetic-assignment">=</span><span class="string-literal">'ignore'</span><span class="grouping">)</span><span class="punctuation">,</span>
     <span class="identifier">make_column_selector</span><span class="grouping">(</span><span class="identifier">dtype_include</span><span class="arithmetic-assignment">=</span><span class="string-literal">'category'</span><span class="grouping">)</span><span class="grouping">)</span><span class="punctuation">,</span>
    <span class="identifier">remainder</span><span class="arithmetic-assignment">=</span><span class="string-literal">'passthrough'</span><span class="grouping">)</span>

<span class="identifier">hist_one_hot</span> <span class="arithmetic-assignment">=</span> <span class="identifier">make_pipeline</span><span class="grouping">(</span><span class="identifier">one_hot_encoder</span><span class="punctuation">,</span>
                             <span class="identifier">HistGradientBoostingRegressor</span><span class="grouping">(</span><span class="identifier">random_state</span><span class="arithmetic-assignment">=</span><span class="int-literal">42</span><span class="grouping">)</span><span class="grouping">)</span>

<span class="comment"># %%</span>
<span class="comment"># Gradient boosting estimator with ordinal encoding</span>
<span class="comment"># -------------------------------------------------</span>
<span class="comment"># Next, we create a pipeline that will treat categorical features as if they</span>
<span class="comment"># were ordered quantities, i.e. the categories will be encoded as 0, 1, 2,</span>
<span class="comment"># etc., and treated as continuous features.</span>

<span class="keyword">from</span> <span class="identifier">sklearn</span><span class="punctuation">.</span><span class="identifier">preprocessing</span> <span class="keyword">import</span> <span class="identifier">OrdinalEncoder</span>
<span class="keyword">import</span> <span class="identifier">numpy</span> <span class="keyword">as</span> <span class="identifier">np</span>

<span class="identifier">ordinal_encoder</span> <span class="arithmetic-assignment">=</span> <span class="identifier">make_column_transformer</span><span class="grouping">(</span>
    <span class="grouping">(</span><span class="identifier">OrdinalEncoder</span><span class="grouping">(</span><span class="identifier">handle_unknown</span><span class="arithmetic-assignment">=</span><span class="string-literal">'use_encoded_value'</span><span class="punctuation">,</span> <span class="identifier">unknown_value</span><span class="arithmetic-assignment">=</span><span class="identifier">np</span><span class="punctuation">.</span><span class="identifier">nan</span><span class="grouping">)</span><span class="punctuation">,</span>
     <span class="identifier">make_column_selector</span><span class="grouping">(</span><span class="identifier">dtype_include</span><span class="arithmetic-assignment">=</span><span class="string-literal">'category'</span><span class="grouping">)</span><span class="grouping">)</span><span class="punctuation">,</span>
    <span class="identifier">remainder</span><span class="arithmetic-assignment">=</span><span class="string-literal">'passthrough'</span><span class="grouping">)</span>

<span class="identifier">hist_ordinal</span> <span class="arithmetic-assignment">=</span> <span class="identifier">make_pipeline</span><span class="grouping">(</span><span class="identifier">ordinal_encoder</span><span class="punctuation">,</span>
                             <span class="identifier">HistGradientBoostingRegressor</span><span class="grouping">(</span><span class="identifier">random_state</span><span class="arithmetic-assignment">=</span><span class="int-literal">42</span><span class="grouping">)</span><span class="grouping">)</span>

<span class="comment"># %%</span>
<span class="comment"># Gradient boosting estimator with native categorical support</span>
<span class="comment"># -----------------------------------------------------------</span>
<span class="comment"># We now create a :class:`~ensemble.HistGradientBoostingRegressor` estimator</span>
<span class="comment"># that will natively handle categorical features. This estimator will not treat</span>
<span class="comment"># categorical features as ordered quantities.</span>
<span class="comment">#</span>
<span class="comment"># Since the :class:`~ensemble.HistGradientBoostingRegressor` requires category</span>
<span class="comment"># values to be encoded in `[0, n_unique_categories - 1]`, we still rely on an</span>
<span class="comment"># :class:`~preprocessing.OrdinalEncoder` to pre-process the data.</span>
<span class="comment">#</span>
<span class="comment"># The main difference between this pipeline and the previous one is that in</span>
<span class="comment"># this one, we let the :class:`~ensemble.HistGradientBoostingRegressor` know</span>
<span class="comment"># which features are categorical.</span>

<span class="comment"># The ordinal encoder will first output the categorical features, and then the</span>
<span class="comment"># continuous (passed-through) features</span>
<span class="identifier">categorical_mask</span> <span class="arithmetic-assignment">=</span> <span class="grouping">(</span><span class="grouping">[</span><span class="bool-literal">True</span><span class="grouping">]</span> <span class="arithmetic-operator">*</span> <span class="identifier">n_categorical_features</span> <span class="arithmetic-operator">+</span>
                    <span class="grouping">[</span><span class="bool-literal">False</span><span class="grouping">]</span> <span class="arithmetic-operator">*</span> <span class="identifier">n_numerical_features</span><span class="grouping">)</span>
<span class="identifier">hist_native</span> <span class="arithmetic-assignment">=</span> <span class="identifier">make_pipeline</span><span class="grouping">(</span>
    <span class="identifier">ordinal_encoder</span><span class="punctuation">,</span>
    <span class="identifier">HistGradientBoostingRegressor</span><span class="grouping">(</span><span class="identifier">random_state</span><span class="arithmetic-assignment">=</span><span class="int-literal">42</span><span class="punctuation">,</span>
                                  <span class="identifier">categorical_features</span><span class="arithmetic-assignment">=</span><span class="identifier">categorical_mask</span><span class="grouping">)</span>
<span class="grouping">)</span>


<span class="comment"># %%</span>
<span class="comment"># Model comparison</span>
<span class="comment"># ----------------</span>
<span class="comment"># Finally, we evaluate the models using cross validation. Here we compare the</span>
<span class="comment"># models performance in terms of</span>
<span class="comment"># :func:`~metrics.mean_absolute_percentage_error` and fit times.</span>

<span class="keyword">from</span> <span class="identifier">sklearn</span><span class="punctuation">.</span><span class="identifier">model_selection</span> <span class="keyword">import</span> <span class="identifier">cross_validate</span>
<span class="keyword">import</span> <span class="identifier">matplotlib</span><span class="punctuation">.</span><span class="identifier">pyplot</span> <span class="keyword">as</span> <span class="identifier">plt</span>

<span class="identifier">scoring</span> <span class="arithmetic-assignment">=</span> <span class="string-literal">"neg_mean_absolute_percentage_error"</span>
<span class="identifier">dropped_result</span> <span class="arithmetic-assignment">=</span> <span class="identifier">cross_validate</span><span class="grouping">(</span><span class="identifier">hist_dropped</span><span class="punctuation">,</span> <span class="identifier">X</span><span class="punctuation">,</span> <span class="identifier">y</span><span class="punctuation">,</span> <span class="identifier">cv</span><span class="arithmetic-assignment">=</span><span class="int-literal">3</span><span class="punctuation">,</span> <span class="identifier">scoring</span><span class="arithmetic-assignment">=</span><span class="identifier">scoring</span><span class="grouping">)</span>
<span class="identifier">one_hot_result</span> <span class="arithmetic-assignment">=</span> <span class="identifier">cross_validate</span><span class="grouping">(</span><span class="identifier">hist_one_hot</span><span class="punctuation">,</span> <span class="identifier">X</span><span class="punctuation">,</span> <span class="identifier">y</span><span class="punctuation">,</span> <span class="identifier">cv</span><span class="arithmetic-assignment">=</span><span class="int-literal">3</span><span class="punctuation">,</span> <span class="identifier">scoring</span><span class="arithmetic-assignment">=</span><span class="identifier">scoring</span><span class="grouping">)</span>
<span class="identifier">ordinal_result</span> <span class="arithmetic-assignment">=</span> <span class="identifier">cross_validate</span><span class="grouping">(</span><span class="identifier">hist_ordinal</span><span class="punctuation">,</span> <span class="identifier">X</span><span class="punctuation">,</span> <span class="identifier">y</span><span class="punctuation">,</span> <span class="identifier">cv</span><span class="arithmetic-assignment">=</span><span class="int-literal">3</span><span class="punctuation">,</span> <span class="identifier">scoring</span><span class="arithmetic-assignment">=</span><span class="identifier">scoring</span><span class="grouping">)</span>
<span class="identifier">native_result</span> <span class="arithmetic-assignment">=</span> <span class="identifier">cross_validate</span><span class="grouping">(</span><span class="identifier">hist_native</span><span class="punctuation">,</span> <span class="identifier">X</span><span class="punctuation">,</span> <span class="identifier">y</span><span class="punctuation">,</span> <span class="identifier">cv</span><span class="arithmetic-assignment">=</span><span class="int-literal">3</span><span class="punctuation">,</span> <span class="identifier">scoring</span><span class="arithmetic-assignment">=</span><span class="identifier">scoring</span><span class="grouping">)</span>


<span class="keyword">def</span> <span class="identifier">plot_results</span><span class="grouping">(</span><span class="identifier">figure_title</span><span class="grouping">)</span><span class="punctuation">:</span>
    <span class="identifier">fig</span><span class="punctuation">,</span> <span class="grouping">(</span><span class="identifier">ax1</span><span class="punctuation">,</span> <span class="identifier">ax2</span><span class="grouping">)</span> <span class="arithmetic-assignment">=</span> <span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">subplots</span><span class="grouping">(</span><span class="int-literal">1</span><span class="punctuation">,</span> <span class="int-literal">2</span><span class="punctuation">,</span> <span class="identifier">figsize</span><span class="arithmetic-assignment">=</span><span class="grouping">(</span><span class="int-literal">12</span><span class="punctuation">,</span> <span class="int-literal">8</span><span class="grouping">)</span><span class="grouping">)</span>

    <span class="identifier">plot_info</span> <span class="arithmetic-assignment">=</span> <span class="grouping">[</span><span class="grouping">(</span><span class="string-literal">'fit_time', 'Fit times (s)'</span><span class="punctuation">,</span> <span class="identifier">ax1</span><span class="punctuation">,</span> <span class="none-literal">None</span><span class="grouping">)</span><span class="punctuation">,</span>
                 <span class="grouping">(</span><span class="string-literal">'test_score', 'Mean Absolute Percentage Error'</span><span class="punctuation">,</span> <span class="identifier">ax2</span><span class="punctuation">,</span>
                  <span class="grouping">(</span><span class="int-literal">0</span><span class="punctuation">,</span> <span class="float-literal">0.20</span><span class="grouping">)</span><span class="grouping">)</span><span class="grouping">]</span>

    <span class="identifier">x</span><span class="punctuation">,</span> <span class="identifier">width</span> <span class="arithmetic-assignment">=</span> <span class="identifier">np</span><span class="punctuation">.</span><span class="identifier">arange</span><span class="grouping">(</span><span class="int-literal">4</span><span class="grouping">)</span><span class="punctuation">,</span> <span class="float-literal">0.9</span>
    <span class="keyword">for</span> <span class="identifier">key</span><span class="punctuation">,</span> <span class="identifier">title</span><span class="punctuation">,</span> <span class="identifier">ax</span><span class="punctuation">,</span> <span class="identifier">y_limit</span> <span class="relational-operator">in</span> <span class="identifier">plot_info</span><span class="punctuation">:</span>
        <span class="identifier">items</span> <span class="arithmetic-assignment">=</span> <span class="grouping">[</span><span class="identifier">dropped_result</span><span class="grouping">[</span><span class="identifier">key</span><span class="grouping">]</span><span class="punctuation">,</span> <span class="identifier">one_hot_result</span><span class="grouping">[</span><span class="identifier">key</span><span class="grouping">]</span><span class="punctuation">,</span> <span class="identifier">ordinal_result</span><span class="grouping">[</span><span class="identifier">key</span><span class="grouping">]</span><span class="punctuation">,</span>
                 <span class="identifier">native_result</span><span class="grouping">[</span><span class="identifier">key</span><span class="grouping">]</span><span class="grouping">]</span>
        <span class="identifier">ax</span><span class="punctuation">.</span><span class="identifier">bar</span><span class="grouping">(</span><span class="identifier">x</span><span class="punctuation">,</span> <span class="grouping">[</span><span class="identifier">np</span><span class="punctuation">.</span><span class="identifier">mean</span><span class="grouping">(</span><span class="identifier">np</span><span class="punctuation">.</span><span class="identifier">abs</span><span class="grouping">(</span><span class="identifier">item</span><span class="grouping">)</span><span class="grouping">)</span> <span class="keyword">for</span> <span class="identifier">item</span> <span class="relational-operator">in</span> <span class="identifier">items</span><span class="grouping">]</span><span class="punctuation">,</span>
               <span class="identifier">width</span><span class="punctuation">,</span> <span class="identifier">yerr</span><span class="arithmetic-assignment">=</span><span class="grouping">[</span><span class="identifier">np</span><span class="punctuation">.</span><span class="identifier">std</span><span class="grouping">(</span><span class="identifier">item</span><span class="grouping">)</span> <span class="keyword">for</span> <span class="identifier">item</span> <span class="relational-operator">in</span> <span class="identifier">items</span><span class="grouping">]</span><span class="punctuation">,</span>
               <span class="identifier">color</span><span class="arithmetic-assignment">=</span><span class="grouping">[</span><span class="string-literal">'C0', 'C1', 'C2', 'C3'</span><span class="grouping">]</span><span class="grouping">)</span>
        <span class="identifier">ax</span><span class="punctuation">.</span><span class="identifier">set</span><span class="grouping">(</span><span class="identifier">xlabel</span><span class="arithmetic-assignment">=</span><span class="string-literal">'Model'</span><span class="punctuation">,</span> <span class="identifier">title</span><span class="arithmetic-assignment">=</span><span class="identifier">title</span><span class="punctuation">,</span> <span class="identifier">xticks</span><span class="arithmetic-assignment">=</span><span class="identifier">x</span><span class="punctuation">,</span>
               <span class="identifier">xticklabels</span><span class="arithmetic-assignment">=</span><span class="grouping">[</span><span class="string-literal">"Dropped", "One Hot", "Ordinal", "Native"</span><span class="grouping">]</span><span class="punctuation">,</span>
               <span class="identifier">ylim</span><span class="arithmetic-assignment">=</span><span class="identifier">y_limit</span><span class="grouping">)</span>
    <span class="identifier">fig</span><span class="punctuation">.</span><span class="identifier">suptitle</span><span class="grouping">(</span><span class="identifier">figure_title</span><span class="grouping">)</span>


<span class="identifier">plot_results</span><span class="grouping">(</span><span class="string-literal">"Gradient Boosting on Adult Census"</span><span class="grouping">)</span>

<span class="comment"># %%</span>
<span class="comment"># We see that the model with one-hot-encoded data is by far the slowest. This</span>
<span class="comment"># is to be expected, since one-hot-encoding creates one additional feature per</span>
<span class="comment"># category value (for each categorical feature), and thus more split points</span>
<span class="comment"># need to be considered during fitting. In theory, we expect the native</span>
<span class="comment"># handling of categorical features to be slightly slower than treating</span>
<span class="comment"># categories as ordered quantities ('Ordinal'), since native handling requires</span>
<span class="comment"># :ref:`sorting categories &lt;categorical_support_gbdt&gt;`. Fitting times should</span>
<span class="comment"># however be close when the number of categories is small, and this may not</span>
<span class="comment"># always be reflected in practice.</span>
<span class="comment">#</span>
<span class="comment"># In terms of prediction performance, dropping the categorical features leads</span>
<span class="comment"># to poorer performance. The three models that use categorical features have</span>
<span class="comment"># comparable error rates, with a slight edge for the native handling.</span>

<span class="comment"># %%</span>
<span class="comment"># Limitting the number of splits</span>
<span class="comment"># ------------------------------</span>
<span class="comment">#</span>
<span class="comment"># In general, one can expect poorer predictions from one-hot-encoded data,</span>
<span class="comment"># especially when the tree depths or the number of nodes are limited: with</span>
<span class="comment"># one-hot-encoded data, one needs more split points, i.e. more depth, in order</span>
<span class="comment"># to recover an equivalent split that could be obtained in one single split</span>
<span class="comment"># point with native handling.</span>
<span class="comment">#</span>
<span class="comment"># This is also true when categories are treated as ordinal quantities: if</span>
<span class="comment"># categories are `A..F` and the best split is `ACF - BDE` the one-hot-encoder</span>
<span class="comment"># model will need 3 split points (one per category in the left node), and the</span>
<span class="comment"># ordinal non-native model will need 4 splits: 1 split to isolate `A`, 1 split</span>
<span class="comment"># to isolate `F`, and 2 splits to isolate `C` from `BCDE`.</span>
<span class="comment">#</span>
<span class="comment"># How strongly the models' performances differ in practice will depend on the</span>
<span class="comment"># dataset and on the flexibility of the trees.</span>
<span class="comment">#</span>
<span class="comment"># To see this, let us re-run the same analysis with under-fitting models where</span>
<span class="comment"># we artificially limit the total number of splits by both limitting the number</span>
<span class="comment"># of trees and the depth of each tree.</span>

<span class="keyword">for</span> <span class="identifier">pipe</span> <span class="relational-operator">in</span> <span class="grouping">(</span><span class="identifier">hist_dropped</span><span class="punctuation">,</span> <span class="identifier">hist_one_hot</span><span class="punctuation">,</span> <span class="identifier">hist_ordinal</span><span class="punctuation">,</span> <span class="identifier">hist_native</span><span class="grouping">)</span><span class="punctuation">:</span>
    <span class="identifier">pipe</span><span class="punctuation">.</span><span class="identifier">set_params</span><span class="grouping">(</span><span class="identifier">histgradientboostingregressor__max_depth</span><span class="arithmetic-assignment">=</span><span class="int-literal">3</span><span class="punctuation">,</span>
                    <span class="identifier">histgradientboostingregressor__max_iter</span><span class="arithmetic-assignment">=</span><span class="int-literal">15</span><span class="grouping">)</span>

<span class="identifier">dropped_result</span> <span class="arithmetic-assignment">=</span> <span class="identifier">cross_validate</span><span class="grouping">(</span><span class="identifier">hist_dropped</span><span class="punctuation">,</span> <span class="identifier">X</span><span class="punctuation">,</span> <span class="identifier">y</span><span class="punctuation">,</span> <span class="identifier">cv</span><span class="arithmetic-assignment">=</span><span class="int-literal">3</span><span class="punctuation">,</span> <span class="identifier">scoring</span><span class="arithmetic-assignment">=</span><span class="identifier">scoring</span><span class="grouping">)</span>
<span class="identifier">one_hot_result</span> <span class="arithmetic-assignment">=</span> <span class="identifier">cross_validate</span><span class="grouping">(</span><span class="identifier">hist_one_hot</span><span class="punctuation">,</span> <span class="identifier">X</span><span class="punctuation">,</span> <span class="identifier">y</span><span class="punctuation">,</span> <span class="identifier">cv</span><span class="arithmetic-assignment">=</span><span class="int-literal">3</span><span class="punctuation">,</span> <span class="identifier">scoring</span><span class="arithmetic-assignment">=</span><span class="identifier">scoring</span><span class="grouping">)</span>
<span class="identifier">ordinal_result</span> <span class="arithmetic-assignment">=</span> <span class="identifier">cross_validate</span><span class="grouping">(</span><span class="identifier">hist_ordinal</span><span class="punctuation">,</span> <span class="identifier">X</span><span class="punctuation">,</span> <span class="identifier">y</span><span class="punctuation">,</span> <span class="identifier">cv</span><span class="arithmetic-assignment">=</span><span class="int-literal">3</span><span class="punctuation">,</span> <span class="identifier">scoring</span><span class="arithmetic-assignment">=</span><span class="identifier">scoring</span><span class="grouping">)</span>
<span class="identifier">native_result</span> <span class="arithmetic-assignment">=</span> <span class="identifier">cross_validate</span><span class="grouping">(</span><span class="identifier">hist_native</span><span class="punctuation">,</span> <span class="identifier">X</span><span class="punctuation">,</span> <span class="identifier">y</span><span class="punctuation">,</span> <span class="identifier">cv</span><span class="arithmetic-assignment">=</span><span class="int-literal">3</span><span class="punctuation">,</span> <span class="identifier">scoring</span><span class="arithmetic-assignment">=</span><span class="identifier">scoring</span><span class="grouping">)</span>

<span class="identifier">plot_results</span><span class="grouping">(</span><span class="string-literal">"Gradient Boosting on Adult Census (few and small trees)"</span><span class="grouping">)</span>

<span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">show</span><span class="grouping">(</span><span class="grouping">)</span>

<span class="comment"># %%</span>
<span class="comment"># The results for these under-fitting models confirm our previous intuition:</span>
<span class="comment"># the native category handling strategy performs the best when the splitting</span>
<span class="comment"># budget is constrained. The two other strategies (one-hot encoding and</span>
<span class="comment"># treating categories as ordinal values) lead to error values comparable</span>
<span class="comment"># to the baseline model that just dropped the categorical features altogether.</span>

    </pre>
  </body>
</html>
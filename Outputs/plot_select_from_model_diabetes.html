<html>
  <head>
    <title>Python Lexical Highliter</title>
    <link rel="stylesheet" href="token_colors.css">
  </head>
  <body>
    <pre><span class="comment">"""
============================================
Model-based and sequential feature selection
============================================

This example illustrates and compares two approaches for feature selection:
:class:`~sklearn.feature_selection.SelectFromModel` which is based on feature
importance, and
:class:`~sklearn.feature_selection.SequentialFeatureSelection` which relies
on a greedy approach.

We use the Diabetes dataset, which consists of 10 features collected from 442
diabetes patients.

Authors: `Manoj Kumar &lt;mks542@nyu.edu&gt;`_,
`Maria Telenczuk &lt;https://github.com/maikia&gt;`_, Nicolas Hug.

License: BSD 3 clause
"""</span>

<span class="identifier">print</span><span class="grouping">(</span><span class="identifier">__doc__</span><span class="grouping">)</span>


<span class="comment"># %%</span>
<span class="comment"># Loading the data</span>
<span class="comment"># ----------------</span>
<span class="comment">#</span>
<span class="comment"># We first load the diabetes dataset which is available from within</span>
<span class="comment"># scikit-learn, and print its description:</span>
<span class="keyword">from</span> <span class="identifier">sklearn</span><span class="punctuation">.</span><span class="identifier">datasets</span> <span class="keyword">import</span> <span class="identifier">load_diabetes</span>

<span class="identifier">diabetes</span> <span class="arithmetic-assignment">=</span> <span class="identifier">load_diabetes</span><span class="grouping">(</span><span class="grouping">)</span>
<span class="identifier">X</span><span class="punctuation">,</span> <span class="identifier">y</span> <span class="arithmetic-assignment">=</span> <span class="identifier">diabetes</span><span class="punctuation">.</span><span class="identifier">data</span><span class="punctuation">,</span> <span class="identifier">diabetes</span><span class="punctuation">.</span><span class="identifier">target</span>
<span class="identifier">print</span><span class="grouping">(</span><span class="identifier">diabetes</span><span class="punctuation">.</span><span class="identifier">DESCR</span><span class="grouping">)</span>

<span class="comment"># %%</span>
<span class="comment"># Feature importance from coefficients</span>
<span class="comment"># ------------------------------------</span>
<span class="comment">#</span>
<span class="comment"># To get an idea of the importance of the features, we are going to use the</span>
<span class="comment"># :class:`~sklearn.linear_model.LassoCV` estimator. The features with the</span>
<span class="comment"># highest absolute `coef_` value are considered the most important.</span>
<span class="comment"># We can observe the coefficients directly without needing to scale them (or</span>
<span class="comment"># scale the data) because from the description above, we know that the features</span>
<span class="comment"># were already standardized.</span>
<span class="comment"># For a more complete example on the interpretations of the coefficients of</span>
<span class="comment"># linear models, you may refer to</span>
<span class="comment"># :ref:`sphx_glr_auto_examples_inspection_plot_linear_model_coefficient_interpretation.py`.</span>
<span class="keyword">import</span> <span class="identifier">matplotlib</span><span class="punctuation">.</span><span class="identifier">pyplot</span> <span class="keyword">as</span> <span class="identifier">plt</span>
<span class="keyword">import</span> <span class="identifier">numpy</span> <span class="keyword">as</span> <span class="identifier">np</span>
<span class="keyword">from</span> <span class="identifier">sklearn</span><span class="punctuation">.</span><span class="identifier">linear_model</span> <span class="keyword">import</span> <span class="identifier">LassoCV</span>

<span class="identifier">lasso</span> <span class="arithmetic-assignment">=</span> <span class="identifier">LassoCV</span><span class="grouping">(</span><span class="grouping">)</span><span class="punctuation">.</span><span class="identifier">fit</span><span class="grouping">(</span><span class="identifier">X</span><span class="punctuation">,</span> <span class="identifier">y</span><span class="grouping">)</span>
<span class="invalid">i</span><span class="invalid">m</span><span class="invalid">p</span><span class="invalid">o</span><span class="invalid">r</span><span class="invalid">t</span><span class="invalid">a</span><span class="invalid">n</span><span class="invalid">c</span><span class="invalid">e</span> <span class="arithmetic-assignment">=</span> <span class="identifier">np</span><span class="punctuation">.</span><span class="identifier">abs</span><span class="grouping">(</span><span class="identifier">lasso</span><span class="punctuation">.</span><span class="identifier">coef_</span><span class="grouping">)</span>
<span class="identifier">feature_names</span> <span class="arithmetic-assignment">=</span> <span class="identifier">np</span><span class="punctuation">.</span><span class="identifier">array</span><span class="grouping">(</span><span class="identifier">diabetes</span><span class="punctuation">.</span><span class="identifier">feature_names</span><span class="grouping">)</span>
<span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">bar</span><span class="grouping">(</span><span class="identifier">height</span><span class="arithmetic-assignment">=</span><span class="invalid">i</span><span class="invalid">m</span><span class="invalid">p</span><span class="invalid">o</span><span class="invalid">r</span><span class="invalid">t</span><span class="invalid">a</span><span class="invalid">n</span><span class="invalid">c</span><span class="invalid">e</span><span class="punctuation">,</span> <span class="identifier">x</span><span class="arithmetic-assignment">=</span><span class="identifier">feature_names</span><span class="grouping">)</span>
<span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">title</span><span class="grouping">(</span><span class="string-literal">"Feature importances via coefficients"</span><span class="grouping">)</span>
<span class="identifier">plt</span><span class="punctuation">.</span><span class="identifier">show</span><span class="grouping">(</span><span class="grouping">)</span>

<span class="comment"># %%</span>
<span class="comment"># Selecting features based on importance</span>
<span class="comment"># --------------------------------------</span>
<span class="comment">#</span>
<span class="comment"># Now we want to select the two features which are the most important according</span>
<span class="comment"># to the coefficients. The :class:`~sklearn.feature_selection.SelectFromModel`</span>
<span class="comment"># is meant just for that. :class:`~sklearn.feature_selection.SelectFromModel`</span>
<span class="comment"># accepts a `threshold` parameter and will select the features whose importance</span>
<span class="comment"># (defined by the coefficients) are above this threshold.</span>
<span class="comment">#</span>
<span class="comment"># Since we want to select only 2 features, we will set this threshold slightly</span>
<span class="comment"># above the coefficient of third most important feature.</span>
<span class="keyword">from</span> <span class="identifier">sklearn</span><span class="punctuation">.</span><span class="identifier">feature_selection</span> <span class="keyword">import</span> <span class="identifier">SelectFromModel</span>
<span class="keyword">from</span> <span class="identifier">time</span> <span class="keyword">import</span> <span class="identifier">time</span>

<span class="identifier">threshold</span> <span class="arithmetic-assignment">=</span> <span class="identifier">np</span><span class="punctuation">.</span><span class="identifier">sort</span><span class="grouping">(</span><span class="invalid">i</span><span class="invalid">m</span><span class="invalid">p</span><span class="invalid">o</span><span class="invalid">r</span><span class="invalid">t</span><span class="invalid">a</span><span class="invalid">n</span><span class="invalid">c</span><span class="invalid">e</span><span class="grouping">)</span><span class="grouping">[</span><span class="arithmetic-operator">-</span><span class="int-literal">3</span><span class="grouping">]</span> <span class="arithmetic-operator">+</span> <span class="float-literal">0.01</span>

<span class="identifier">tic</span> <span class="arithmetic-assignment">=</span> <span class="identifier">time</span><span class="grouping">(</span><span class="grouping">)</span>
<span class="identifier">sfm</span> <span class="arithmetic-assignment">=</span> <span class="identifier">SelectFromModel</span><span class="grouping">(</span><span class="identifier">lasso</span><span class="punctuation">,</span> <span class="identifier">threshold</span><span class="arithmetic-assignment">=</span><span class="identifier">threshold</span><span class="grouping">)</span><span class="punctuation">.</span><span class="identifier">fit</span><span class="grouping">(</span><span class="identifier">X</span><span class="punctuation">,</span> <span class="identifier">y</span><span class="grouping">)</span>
<span class="identifier">toc</span> <span class="arithmetic-assignment">=</span> <span class="identifier">time</span><span class="grouping">(</span><span class="grouping">)</span>
<span class="identifier">print</span><span class="grouping">(</span><span class="string-literal">"Features selected by SelectFromModel: "</span>
      <span class="identifier">f</span><span class="string-literal">"{feature_names[sfm.get_support()]}"</span><span class="grouping">)</span>
<span class="identifier">print</span><span class="grouping">(</span><span class="identifier">f</span><span class="string-literal">"Done in {toc - tic:.3f}s"</span><span class="grouping">)</span>

<span class="comment"># %%</span>
<span class="comment"># Selecting features with Sequential Feature Selection</span>
<span class="comment"># ----------------------------------------------------</span>
<span class="comment">#</span>
<span class="comment"># Another way of selecting features is to use</span>
<span class="comment"># :class:`~sklearn.feature_selection.SequentialFeatureSelector`</span>
<span class="comment"># (SFS). SFS is a greedy procedure where, at each iteration, we choose the best</span>
<span class="comment"># new feature to add to our selected features based a cross-validation score.</span>
<span class="comment"># That is, we start with 0 features and choose the best single feature with the</span>
<span class="comment"># highest score. The procedure is repeated until we reach the desired number of</span>
<span class="comment"># selected features.</span>
<span class="comment">#</span>
<span class="comment"># We can also go in the reverse direction (backward SFS), *i.e.* start with all</span>
<span class="comment"># the features and greedily choose features to remove one by one. We illustrate</span>
<span class="comment"># both approaches here.</span>

<span class="keyword">from</span> <span class="identifier">sklearn</span><span class="punctuation">.</span><span class="identifier">feature_selection</span> <span class="keyword">import</span> <span class="identifier">SequentialFeatureSelector</span>

<span class="identifier">tic_fwd</span> <span class="arithmetic-assignment">=</span> <span class="identifier">time</span><span class="grouping">(</span><span class="grouping">)</span>
<span class="identifier">sfs_forward</span> <span class="arithmetic-assignment">=</span> <span class="identifier">SequentialFeatureSelector</span><span class="grouping">(</span><span class="identifier">lasso</span><span class="punctuation">,</span> <span class="identifier">n_features_to_select</span><span class="arithmetic-assignment">=</span><span class="int-literal">2</span><span class="punctuation">,</span>
                                        <span class="identifier">direction</span><span class="arithmetic-assignment">=</span><span class="string-literal">'forward'</span><span class="grouping">)</span><span class="punctuation">.</span><span class="identifier">fit</span><span class="grouping">(</span><span class="identifier">X</span><span class="punctuation">,</span> <span class="identifier">y</span><span class="grouping">)</span>
<span class="identifier">toc_fwd</span> <span class="arithmetic-assignment">=</span> <span class="identifier">time</span><span class="grouping">(</span><span class="grouping">)</span>

<span class="identifier">tic_bwd</span> <span class="arithmetic-assignment">=</span> <span class="identifier">time</span><span class="grouping">(</span><span class="grouping">)</span>
<span class="identifier">sfs_backward</span> <span class="arithmetic-assignment">=</span> <span class="identifier">SequentialFeatureSelector</span><span class="grouping">(</span><span class="identifier">lasso</span><span class="punctuation">,</span> <span class="identifier">n_features_to_select</span><span class="arithmetic-assignment">=</span><span class="int-literal">2</span><span class="punctuation">,</span>
                                         <span class="identifier">direction</span><span class="arithmetic-assignment">=</span><span class="string-literal">'backward'</span><span class="grouping">)</span><span class="punctuation">.</span><span class="identifier">fit</span><span class="grouping">(</span><span class="identifier">X</span><span class="punctuation">,</span> <span class="identifier">y</span><span class="grouping">)</span>
<span class="identifier">toc_bwd</span> <span class="arithmetic-assignment">=</span> <span class="identifier">time</span><span class="grouping">(</span><span class="grouping">)</span>

<span class="identifier">print</span><span class="grouping">(</span><span class="string-literal">"Features selected by forward sequential selection: "</span>
      <span class="identifier">f</span><span class="string-literal">"{feature_names[sfs_forward.get_support()]}"</span><span class="grouping">)</span>
<span class="identifier">print</span><span class="grouping">(</span><span class="identifier">f</span><span class="string-literal">"Done in {toc_fwd - tic_fwd:.3f}s"</span><span class="grouping">)</span>
<span class="identifier">print</span><span class="grouping">(</span><span class="string-literal">"Features selected by backward sequential selection: "</span>
      <span class="identifier">f</span><span class="string-literal">"{feature_names[sfs_backward.get_support()]}"</span><span class="grouping">)</span>
<span class="identifier">print</span><span class="grouping">(</span><span class="identifier">f</span><span class="string-literal">"Done in {toc_bwd - tic_bwd:.3f}s"</span><span class="grouping">)</span>

<span class="comment"># %%</span>
<span class="comment"># Discussion</span>
<span class="comment"># ----------</span>
<span class="comment">#</span>
<span class="comment"># Interestingly, forward and backward selection have selected the same set of</span>
<span class="comment"># features. In general, this isn't the case and the two methods would lead to</span>
<span class="comment"># different results.</span>
<span class="comment">#</span>
<span class="comment"># We also note that the features selected by SFS differ from those selected by</span>
<span class="comment"># feature importance: SFS selects `bmi` instead of `s1`. This does sound</span>
<span class="comment"># reasonable though, since `bmi` corresponds to the third most important</span>
<span class="comment"># feature according to the coefficients. It is quite remarkable considering</span>
<span class="comment"># that SFS makes no use of the coefficients at all.</span>
<span class="comment">#</span>
<span class="comment"># To finish with, we should note that</span>
<span class="comment"># :class:`~sklearn.feature_selection.SelectFromModel` is significantly faster</span>
<span class="comment"># than SFS. Indeed, :class:`~sklearn.feature_selection.SelectFromModel` only</span>
<span class="comment"># needs to fit a model once, while SFS needs to cross-validate many different</span>
<span class="comment"># models for each of the iterations. SFS however works with any model, while</span>
<span class="comment"># :class:`~sklearn.feature_selection.SelectFromModel` requires the underlying</span>
<span class="comment"># estimator to expose a `coef_` attribute or a `feature_importances_`</span>
<span class="comment"># attribute. The forward SFS is faster than the backward SFS because it only</span>
<span class="comment"># needs to perform `n_features_to_select = 2` iterations, while the backward</span>
<span class="comment"># SFS needs to perform `n_features - n_features_to_select = 8` iterations.</span>

    </pre>
  </body>
</html>